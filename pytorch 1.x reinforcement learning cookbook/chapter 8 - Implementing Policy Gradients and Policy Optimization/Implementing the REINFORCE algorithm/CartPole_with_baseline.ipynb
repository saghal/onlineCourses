{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartPole with baseline",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzHKMVoJXX4h"
      },
      "source": [
        "## import libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "env = gym.make('CartPole-v0')"
      ],
      "metadata": {
        "id": "0ydx3MJ0FpZw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PolicyNetwork():\n",
        "    def __init__(self, n_state, n_action, n_hidden=50, lr=0.001):\n",
        "        self.model = nn.Sequential(\n",
        "                        nn.Linear(n_state, n_hidden),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(n_hidden, n_action),\n",
        "                        nn.Softmax(),\n",
        "                        )\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr)\n",
        "    \n",
        "\n",
        "    def predict(self, s):\n",
        "      return self.model(torch.Tensor(s))\n",
        "\n",
        "    def update(self, advantages, log_probs):\n",
        "      policy_gradient = []\n",
        "      for log_prob, Gt in zip(log_probs, advantages):\n",
        "        policy_gradient.append(-log_prob * Gt)\n",
        "      loss = torch.stack(policy_gradient).sum()\n",
        "      self.optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "\n",
        "    def get_action(self, s):\n",
        "      probs = self.predict(s)\n",
        "      action = torch.multinomial(probs, 1).item()\n",
        "      log_prob = torch.log(probs[action])\n",
        "      return action, log_prob\n"
      ],
      "metadata": {
        "id": "QZmTbk_6Fw44"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ValueNetwork():\n",
        "  \n",
        "  def __init__(self, n_state, n_hidden=50, lr=0.05):\n",
        "    self.criterion = torch.nn.MSELoss()\n",
        "    self.model = torch.nn.Sequential(\n",
        "                  torch.nn.Linear(n_state, n_hidden),\n",
        "                  torch.nn.ReLU(),\n",
        "                  torch.nn.Linear(n_hidden, 1))\n",
        "    self.optimizer = torch.optim.Adam(self.model.parameters(), lr)\n",
        "  \n",
        "  def update(self, s, y):\n",
        "    y_pred = self.model(torch.Tensor(s))\n",
        "    loss = self.criterion(y_pred,Variable(torch.Tensor(y)))\n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "\n",
        "  def predict(self, s):\n",
        "    with torch.no_grad():\n",
        "      return self.model(torch.Tensor(s))"
      ],
      "metadata": {
        "id": "8psCX_lJpWR0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reinforce(env, estimator_policy, estimator_value,n_episode, gamma=1.0):\n",
        "  for episode in range(n_episode):\n",
        "    log_probs = []\n",
        "    states = []\n",
        "    rewards = []\n",
        "    state = env.reset()\n",
        "    while True:\n",
        "      states.append(state)\n",
        "      action, log_prob = estimator_policy.get_action(state)\n",
        "      next_state, reward, is_done, _ = env.step(action)\n",
        "      total_reward_episode[episode] += reward\n",
        "      log_probs.append(log_prob)\n",
        "      rewards.append(reward)\n",
        "      if is_done:\n",
        "        Gt = 0\n",
        "        pw = 0\n",
        "        returns = []\n",
        "        for t in range(len(states)-1, -1, -1):\n",
        "          Gt += gamma ** pw * rewards[t]\n",
        "          pw += 1\n",
        "          returns.append(Gt)\n",
        "        returns = returns[::-1]\n",
        "        returns = torch.tensor(returns)\n",
        "        baseline_values = estimator_value.predict(states)\n",
        "        advantages = returns - baseline_values\n",
        "        estimator_value.update(states, returns)\n",
        "        estimator_policy.update(advantages, log_probs)\n",
        "        print('Episode: {}, total reward: {}'.format(episode, total_reward_episode[episode]))\n",
        "        break\n",
        "      state = next_state"
      ],
      "metadata": {
        "id": "fOA8pc6xGgdS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_state = env.observation_space.shape[0]\n",
        "n_action = env.action_space.n\n",
        "n_hidden_p = 64\n",
        "lr_p = 0.003\n",
        "policy_net = PolicyNetwork(n_state, n_action, n_hidden_p, lr_p)"
      ],
      "metadata": {
        "id": "44aQgZCHHP48"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden_v = 64\n",
        "lr_v = 0.003\n",
        "value_net = ValueNetwork(n_state, n_hidden_v, lr_v)\n",
        "gamma = 0.9"
      ],
      "metadata": {
        "id": "mKqCH59erfu0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_episode = 2000\n",
        "total_reward_episode = [0] * n_episode\n",
        "reinforce(env, policy_net, value_net, n_episode, gamma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5wexkd3rn50",
        "outputId": "c87bfef3-dafc-4a63-9fa0-f524ad4bb288"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([38])) that is different to the input size (torch.Size([38, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, total reward: 19.0\n",
            "Episode: 1, total reward: 38.0\n",
            "Episode: 2, total reward: 14.0\n",
            "Episode: 3, total reward: 16.0\n",
            "Episode: 4, total reward: 14.0\n",
            "Episode: 5, total reward: 15.0\n",
            "Episode: 6, total reward: 24.0\n",
            "Episode: 7, total reward: 16.0\n",
            "Episode: 8, total reward: 17.0\n",
            "Episode: 9, total reward: 15.0\n",
            "Episode: 10, total reward: 12.0\n",
            "Episode: 11, total reward: 15.0\n",
            "Episode: 12, total reward: 17.0\n",
            "Episode: 13, total reward: 27.0\n",
            "Episode: 14, total reward: 14.0\n",
            "Episode: 15, total reward: 16.0\n",
            "Episode: 16, total reward: 21.0\n",
            "Episode: 17, total reward: 20.0\n",
            "Episode: 18, total reward: 10.0\n",
            "Episode: 19, total reward: 13.0\n",
            "Episode: 20, total reward: 19.0\n",
            "Episode: 21, total reward: 19.0\n",
            "Episode: 22, total reward: 17.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([15])) that is different to the input size (torch.Size([15, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([24])) that is different to the input size (torch.Size([24, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([17])) that is different to the input size (torch.Size([17, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([27])) that is different to the input size (torch.Size([27, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([13])) that is different to the input size (torch.Size([13, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([26])) that is different to the input size (torch.Size([26, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 23, total reward: 26.0\n",
            "Episode: 24, total reward: 13.0\n",
            "Episode: 25, total reward: 26.0\n",
            "Episode: 26, total reward: 13.0\n",
            "Episode: 27, total reward: 35.0\n",
            "Episode: 28, total reward: 28.0\n",
            "Episode: 29, total reward: 46.0\n",
            "Episode: 30, total reward: 23.0\n",
            "Episode: 31, total reward: 26.0\n",
            "Episode: 32, total reward: 26.0\n",
            "Episode: 33, total reward: 23.0\n",
            "Episode: 34, total reward: 11.0\n",
            "Episode: 35, total reward: 18.0\n",
            "Episode: 36, total reward: 42.0\n",
            "Episode: 37, total reward: 16.0\n",
            "Episode: 38, total reward: 31.0\n",
            "Episode: 39, total reward: 12.0\n",
            "Episode: 40, total reward: 22.0\n",
            "Episode: 41, total reward: 29.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([28])) that is different to the input size (torch.Size([28, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([46])) that is different to the input size (torch.Size([46, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([23])) that is different to the input size (torch.Size([23, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([11])) that is different to the input size (torch.Size([11, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([18])) that is different to the input size (torch.Size([18, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([42])) that is different to the input size (torch.Size([42, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([31])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([22])) that is different to the input size (torch.Size([22, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([29])) that is different to the input size (torch.Size([29, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([39])) that is different to the input size (torch.Size([39, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 42, total reward: 15.0\n",
            "Episode: 43, total reward: 39.0\n",
            "Episode: 44, total reward: 12.0\n",
            "Episode: 45, total reward: 21.0\n",
            "Episode: 46, total reward: 28.0\n",
            "Episode: 47, total reward: 25.0\n",
            "Episode: 48, total reward: 20.0\n",
            "Episode: 49, total reward: 18.0\n",
            "Episode: 50, total reward: 32.0\n",
            "Episode: 51, total reward: 13.0\n",
            "Episode: 52, total reward: 26.0\n",
            "Episode: 53, total reward: 10.0\n",
            "Episode: 54, total reward: 37.0\n",
            "Episode: 55, total reward: 42.0\n",
            "Episode: 56, total reward: 10.0\n",
            "Episode: 57, total reward: 17.0\n",
            "Episode: 58, total reward: 17.0\n",
            "Episode: 59, total reward: 16.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([25])) that is different to the input size (torch.Size([25, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([37])) that is different to the input size (torch.Size([37, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 60, total reward: 42.0\n",
            "Episode: 61, total reward: 21.0\n",
            "Episode: 62, total reward: 15.0\n",
            "Episode: 63, total reward: 32.0\n",
            "Episode: 64, total reward: 20.0\n",
            "Episode: 65, total reward: 14.0\n",
            "Episode: 66, total reward: 13.0\n",
            "Episode: 67, total reward: 41.0\n",
            "Episode: 68, total reward: 27.0\n",
            "Episode: 69, total reward: 17.0\n",
            "Episode: 70, total reward: 24.0\n",
            "Episode: 71, total reward: 33.0\n",
            "Episode: 72, total reward: 28.0\n",
            "Episode: 73, total reward: 24.0\n",
            "Episode: 74, total reward: 13.0\n",
            "Episode: 75, total reward: 21.0\n",
            "Episode: 76, total reward: 33.0\n",
            "Episode: 77, total reward: 46.0\n",
            "Episode: 78, total reward: 39.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([41])) that is different to the input size (torch.Size([41, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([33])) that is different to the input size (torch.Size([33, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 79, total reward: 14.0\n",
            "Episode: 80, total reward: 32.0\n",
            "Episode: 81, total reward: 32.0\n",
            "Episode: 82, total reward: 23.0\n",
            "Episode: 83, total reward: 16.0\n",
            "Episode: 84, total reward: 30.0\n",
            "Episode: 85, total reward: 26.0\n",
            "Episode: 86, total reward: 28.0\n",
            "Episode: 87, total reward: 52.0\n",
            "Episode: 88, total reward: 19.0\n",
            "Episode: 89, total reward: 37.0\n",
            "Episode: 90, total reward: 20.0\n",
            "Episode: 91, total reward: 13.0\n",
            "Episode: 92, total reward: 19.0\n",
            "Episode: 93, total reward: 43.0\n",
            "Episode: 94, total reward: 47.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([30])) that is different to the input size (torch.Size([30, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([52])) that is different to the input size (torch.Size([52, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([43])) that is different to the input size (torch.Size([43, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([47])) that is different to the input size (torch.Size([47, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 95, total reward: 39.0\n",
            "Episode: 96, total reward: 23.0\n",
            "Episode: 97, total reward: 32.0\n",
            "Episode: 98, total reward: 43.0\n",
            "Episode: 99, total reward: 32.0\n",
            "Episode: 100, total reward: 15.0\n",
            "Episode: 101, total reward: 11.0\n",
            "Episode: 102, total reward: 48.0\n",
            "Episode: 103, total reward: 38.0\n",
            "Episode: 104, total reward: 29.0\n",
            "Episode: 105, total reward: 12.0\n",
            "Episode: 106, total reward: 16.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([48])) that is different to the input size (torch.Size([48, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([83])) that is different to the input size (torch.Size([83, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 107, total reward: 83.0\n",
            "Episode: 108, total reward: 16.0\n",
            "Episode: 109, total reward: 30.0\n",
            "Episode: 110, total reward: 29.0\n",
            "Episode: 111, total reward: 41.0\n",
            "Episode: 112, total reward: 22.0\n",
            "Episode: 113, total reward: 36.0\n",
            "Episode: 114, total reward: 30.0\n",
            "Episode: 115, total reward: 16.0\n",
            "Episode: 116, total reward: 57.0\n",
            "Episode: 117, total reward: 21.0\n",
            "Episode: 118, total reward: 27.0\n",
            "Episode: 119, total reward: 19.0\n",
            "Episode: 120, total reward: 30.0\n",
            "Episode: 121, total reward: 42.0\n",
            "Episode: 122, total reward: 21.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([36])) that is different to the input size (torch.Size([36, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([57])) that is different to the input size (torch.Size([57, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([91])) that is different to the input size (torch.Size([91, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 123, total reward: 16.0\n",
            "Episode: 124, total reward: 91.0\n",
            "Episode: 125, total reward: 27.0\n",
            "Episode: 126, total reward: 35.0\n",
            "Episode: 127, total reward: 23.0\n",
            "Episode: 128, total reward: 24.0\n",
            "Episode: 129, total reward: 35.0\n",
            "Episode: 130, total reward: 49.0\n",
            "Episode: 131, total reward: 18.0\n",
            "Episode: 132, total reward: 24.0\n",
            "Episode: 133, total reward: 41.0\n",
            "Episode: 134, total reward: 65.0\n",
            "Episode: 135, total reward: 25.0\n",
            "Episode: 136, total reward: 18.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([49])) that is different to the input size (torch.Size([49, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([65])) that is different to the input size (torch.Size([65, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([44])) that is different to the input size (torch.Size([44, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 137, total reward: 20.0\n",
            "Episode: 138, total reward: 91.0\n",
            "Episode: 139, total reward: 44.0\n",
            "Episode: 140, total reward: 21.0\n",
            "Episode: 141, total reward: 27.0\n",
            "Episode: 142, total reward: 57.0\n",
            "Episode: 143, total reward: 52.0\n",
            "Episode: 144, total reward: 36.0\n",
            "Episode: 145, total reward: 12.0\n",
            "Episode: 146, total reward: 39.0\n",
            "Episode: 147, total reward: 20.0\n",
            "Episode: 148, total reward: 73.0\n",
            "Episode: 149, total reward: 29.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([73])) that is different to the input size (torch.Size([73, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([80])) that is different to the input size (torch.Size([80, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([55])) that is different to the input size (torch.Size([55, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([70])) that is different to the input size (torch.Size([70, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([61])) that is different to the input size (torch.Size([61, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 150, total reward: 23.0\n",
            "Episode: 151, total reward: 80.0\n",
            "Episode: 152, total reward: 19.0\n",
            "Episode: 153, total reward: 55.0\n",
            "Episode: 154, total reward: 70.0\n",
            "Episode: 155, total reward: 61.0\n",
            "Episode: 156, total reward: 16.0\n",
            "Episode: 157, total reward: 43.0\n",
            "Episode: 158, total reward: 15.0\n",
            "Episode: 159, total reward: 36.0\n",
            "Episode: 160, total reward: 56.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([58])) that is different to the input size (torch.Size([58, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([34])) that is different to the input size (torch.Size([34, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([45])) that is different to the input size (torch.Size([45, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 161, total reward: 58.0\n",
            "Episode: 162, total reward: 65.0\n",
            "Episode: 163, total reward: 18.0\n",
            "Episode: 164, total reward: 18.0\n",
            "Episode: 165, total reward: 34.0\n",
            "Episode: 166, total reward: 34.0\n",
            "Episode: 167, total reward: 36.0\n",
            "Episode: 168, total reward: 18.0\n",
            "Episode: 169, total reward: 45.0\n",
            "Episode: 170, total reward: 38.0\n",
            "Episode: 171, total reward: 67.0\n",
            "Episode: 172, total reward: 36.0\n",
            "Episode: 173, total reward: 28.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([67])) that is different to the input size (torch.Size([67, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([53])) that is different to the input size (torch.Size([53, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 174, total reward: 15.0\n",
            "Episode: 175, total reward: 24.0\n",
            "Episode: 176, total reward: 28.0\n",
            "Episode: 177, total reward: 58.0\n",
            "Episode: 178, total reward: 61.0\n",
            "Episode: 179, total reward: 25.0\n",
            "Episode: 180, total reward: 33.0\n",
            "Episode: 181, total reward: 23.0\n",
            "Episode: 182, total reward: 80.0\n",
            "Episode: 183, total reward: 53.0\n",
            "Episode: 184, total reward: 34.0\n",
            "Episode: 185, total reward: 47.0\n",
            "Episode: 186, total reward: 11.0\n",
            "Episode: 187, total reward: 20.0\n",
            "Episode: 188, total reward: 12.0\n",
            "Episode: 189, total reward: 48.0\n",
            "Episode: 190, total reward: 15.0\n",
            "Episode: 191, total reward: 113.0\n",
            "Episode: 192, total reward: 127.0\n",
            "Episode: 193, total reward: 37.0\n",
            "Episode: 194, total reward: 76.0\n",
            "Episode: 195, total reward: 96.0\n",
            "Episode: 196, total reward: 13.0\n",
            "Episode: 197, total reward: 56.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([113])) that is different to the input size (torch.Size([113, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([127])) that is different to the input size (torch.Size([127, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([76])) that is different to the input size (torch.Size([76, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([96])) that is different to the input size (torch.Size([96, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 198, total reward: 55.0\n",
            "Episode: 199, total reward: 103.0\n",
            "Episode: 200, total reward: 28.0\n",
            "Episode: 201, total reward: 31.0\n",
            "Episode: 202, total reward: 34.0\n",
            "Episode: 203, total reward: 66.0\n",
            "Episode: 204, total reward: 51.0\n",
            "Episode: 205, total reward: 59.0\n",
            "Episode: 206, total reward: 91.0\n",
            "Episode: 207, total reward: 25.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([103])) that is different to the input size (torch.Size([103, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([66])) that is different to the input size (torch.Size([66, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([51])) that is different to the input size (torch.Size([51, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([59])) that is different to the input size (torch.Size([59, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 208, total reward: 67.0\n",
            "Episode: 209, total reward: 42.0\n",
            "Episode: 210, total reward: 62.0\n",
            "Episode: 211, total reward: 23.0\n",
            "Episode: 212, total reward: 59.0\n",
            "Episode: 213, total reward: 30.0\n",
            "Episode: 214, total reward: 39.0\n",
            "Episode: 215, total reward: 34.0\n",
            "Episode: 216, total reward: 110.0\n",
            "Episode: 217, total reward: 44.0\n",
            "Episode: 218, total reward: 33.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([62])) that is different to the input size (torch.Size([62, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([110])) that is different to the input size (torch.Size([110, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 219, total reward: 35.0\n",
            "Episode: 220, total reward: 38.0\n",
            "Episode: 221, total reward: 47.0\n",
            "Episode: 222, total reward: 25.0\n",
            "Episode: 223, total reward: 94.0\n",
            "Episode: 224, total reward: 103.0\n",
            "Episode: 225, total reward: 39.0\n",
            "Episode: 226, total reward: 45.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([94])) that is different to the input size (torch.Size([94, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([200])) that is different to the input size (torch.Size([200, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([143])) that is different to the input size (torch.Size([143, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 227, total reward: 200.0\n",
            "Episode: 228, total reward: 143.0\n",
            "Episode: 229, total reward: 64.0\n",
            "Episode: 230, total reward: 79.0\n",
            "Episode: 231, total reward: 23.0\n",
            "Episode: 232, total reward: 98.0\n",
            "Episode: 233, total reward: 64.0\n",
            "Episode: 234, total reward: 97.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([79])) that is different to the input size (torch.Size([79, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([98])) that is different to the input size (torch.Size([98, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([97])) that is different to the input size (torch.Size([97, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 235, total reward: 39.0\n",
            "Episode: 236, total reward: 44.0\n",
            "Episode: 237, total reward: 65.0\n",
            "Episode: 238, total reward: 59.0\n",
            "Episode: 239, total reward: 18.0\n",
            "Episode: 240, total reward: 30.0\n",
            "Episode: 241, total reward: 39.0\n",
            "Episode: 242, total reward: 88.0\n",
            "Episode: 243, total reward: 104.0\n",
            "Episode: 244, total reward: 42.0\n",
            "Episode: 245, total reward: 63.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([88])) that is different to the input size (torch.Size([88, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([104])) that is different to the input size (torch.Size([104, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([63])) that is different to the input size (torch.Size([63, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 246, total reward: 42.0\n",
            "Episode: 247, total reward: 66.0\n",
            "Episode: 248, total reward: 45.0\n",
            "Episode: 249, total reward: 24.0\n",
            "Episode: 250, total reward: 16.0\n",
            "Episode: 251, total reward: 141.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([141])) that is different to the input size (torch.Size([141, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([86])) that is different to the input size (torch.Size([86, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 252, total reward: 32.0\n",
            "Episode: 253, total reward: 113.0\n",
            "Episode: 254, total reward: 86.0\n",
            "Episode: 255, total reward: 82.0\n",
            "Episode: 256, total reward: 76.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([82])) that is different to the input size (torch.Size([82, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([68])) that is different to the input size (torch.Size([68, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 257, total reward: 32.0\n",
            "Episode: 258, total reward: 68.0\n",
            "Episode: 259, total reward: 149.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([149])) that is different to the input size (torch.Size([149, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([71])) that is different to the input size (torch.Size([71, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 260, total reward: 65.0\n",
            "Episode: 261, total reward: 71.0\n",
            "Episode: 262, total reward: 66.0\n",
            "Episode: 263, total reward: 125.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([125])) that is different to the input size (torch.Size([125, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([95])) that is different to the input size (torch.Size([95, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([117])) that is different to the input size (torch.Size([117, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 264, total reward: 95.0\n",
            "Episode: 265, total reward: 117.0\n",
            "Episode: 266, total reward: 25.0\n",
            "Episode: 267, total reward: 104.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([120])) that is different to the input size (torch.Size([120, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([78])) that is different to the input size (torch.Size([78, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([92])) that is different to the input size (torch.Size([92, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 268, total reward: 120.0\n",
            "Episode: 269, total reward: 78.0\n",
            "Episode: 270, total reward: 92.0\n",
            "Episode: 271, total reward: 63.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([84])) that is different to the input size (torch.Size([84, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 272, total reward: 84.0\n",
            "Episode: 273, total reward: 51.0\n",
            "Episode: 274, total reward: 32.0\n",
            "Episode: 275, total reward: 41.0\n",
            "Episode: 276, total reward: 42.0\n",
            "Episode: 277, total reward: 56.0\n",
            "Episode: 278, total reward: 44.0\n",
            "Episode: 279, total reward: 82.0\n",
            "Episode: 280, total reward: 74.0\n",
            "Episode: 281, total reward: 99.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([74])) that is different to the input size (torch.Size([74, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([99])) that is different to the input size (torch.Size([99, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 282, total reward: 88.0\n",
            "Episode: 283, total reward: 114.0\n",
            "Episode: 284, total reward: 76.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([114])) that is different to the input size (torch.Size([114, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([142])) that is different to the input size (torch.Size([142, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 285, total reward: 142.0\n",
            "Episode: 286, total reward: 79.0\n",
            "Episode: 287, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([72])) that is different to the input size (torch.Size([72, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([109])) that is different to the input size (torch.Size([109, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 288, total reward: 72.0\n",
            "Episode: 289, total reward: 109.0\n",
            "Episode: 290, total reward: 34.0\n",
            "Episode: 291, total reward: 114.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([111])) that is different to the input size (torch.Size([111, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([89])) that is different to the input size (torch.Size([89, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 292, total reward: 111.0\n",
            "Episode: 293, total reward: 89.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([93])) that is different to the input size (torch.Size([93, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([123])) that is different to the input size (torch.Size([123, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 294, total reward: 93.0\n",
            "Episode: 295, total reward: 123.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([137])) that is different to the input size (torch.Size([137, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 296, total reward: 137.0\n",
            "Episode: 297, total reward: 59.0\n",
            "Episode: 298, total reward: 104.0\n",
            "Episode: 299, total reward: 141.0\n",
            "Episode: 300, total reward: 93.0\n",
            "Episode: 301, total reward: 126.0\n",
            "Episode: 302, total reward: 99.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([126])) that is different to the input size (torch.Size([126, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 303, total reward: 104.0\n",
            "Episode: 304, total reward: 142.0\n",
            "Episode: 305, total reward: 36.0\n",
            "Episode: 306, total reward: 110.0\n",
            "Episode: 307, total reward: 111.0\n",
            "Episode: 308, total reward: 104.0\n",
            "Episode: 309, total reward: 147.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([147])) that is different to the input size (torch.Size([147, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([156])) that is different to the input size (torch.Size([156, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 310, total reward: 156.0\n",
            "Episode: 311, total reward: 102.0\n",
            "Episode: 312, total reward: 33.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([102])) that is different to the input size (torch.Size([102, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([140])) that is different to the input size (torch.Size([140, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 313, total reward: 140.0\n",
            "Episode: 314, total reward: 158.0\n",
            "Episode: 315, total reward: 26.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([158])) that is different to the input size (torch.Size([158, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([163])) that is different to the input size (torch.Size([163, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 316, total reward: 163.0\n",
            "Episode: 317, total reward: 197.0\n",
            "Episode: 318, total reward: 88.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([197])) that is different to the input size (torch.Size([197, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([132])) that is different to the input size (torch.Size([132, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 319, total reward: 132.0\n",
            "Episode: 320, total reward: 118.0\n",
            "Episode: 321, total reward: 54.0\n",
            "Episode: 322, total reward: 61.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([118])) that is different to the input size (torch.Size([118, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([54])) that is different to the input size (torch.Size([54, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 323, total reward: 120.0\n",
            "Episode: 324, total reward: 164.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([164])) that is different to the input size (torch.Size([164, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([122])) that is different to the input size (torch.Size([122, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([124])) that is different to the input size (torch.Size([124, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 325, total reward: 122.0\n",
            "Episode: 326, total reward: 124.0\n",
            "Episode: 327, total reward: 116.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([116])) that is different to the input size (torch.Size([116, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([145])) that is different to the input size (torch.Size([145, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([159])) that is different to the input size (torch.Size([159, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 328, total reward: 145.0\n",
            "Episode: 329, total reward: 159.0\n",
            "Episode: 330, total reward: 200.0\n",
            "Episode: 331, total reward: 141.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([139])) that is different to the input size (torch.Size([139, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([181])) that is different to the input size (torch.Size([181, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 332, total reward: 139.0\n",
            "Episode: 333, total reward: 83.0\n",
            "Episode: 334, total reward: 181.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([151])) that is different to the input size (torch.Size([151, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([101])) that is different to the input size (torch.Size([101, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 335, total reward: 151.0\n",
            "Episode: 336, total reward: 42.0\n",
            "Episode: 337, total reward: 101.0\n",
            "Episode: 338, total reward: 200.0\n",
            "Episode: 339, total reward: 141.0\n",
            "Episode: 340, total reward: 123.0\n",
            "Episode: 341, total reward: 140.0\n",
            "Episode: 342, total reward: 181.0\n",
            "Episode: 343, total reward: 163.0\n",
            "Episode: 344, total reward: 126.0\n",
            "Episode: 345, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([191])) that is different to the input size (torch.Size([191, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 346, total reward: 191.0\n",
            "Episode: 347, total reward: 110.0\n",
            "Episode: 348, total reward: 147.0\n",
            "Episode: 349, total reward: 173.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([173])) that is different to the input size (torch.Size([173, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 350, total reward: 122.0\n",
            "Episode: 351, total reward: 133.0\n",
            "Episode: 352, total reward: 113.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([133])) that is different to the input size (torch.Size([133, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 353, total reward: 200.0\n",
            "Episode: 354, total reward: 183.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([183])) that is different to the input size (torch.Size([183, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([77])) that is different to the input size (torch.Size([77, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 355, total reward: 77.0\n",
            "Episode: 356, total reward: 112.0\n",
            "Episode: 357, total reward: 73.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([112])) that is different to the input size (torch.Size([112, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 358, total reward: 66.0\n",
            "Episode: 359, total reward: 200.0\n",
            "Episode: 360, total reward: 41.0\n",
            "Episode: 361, total reward: 111.0\n",
            "Episode: 362, total reward: 109.0\n",
            "Episode: 363, total reward: 167.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([167])) that is different to the input size (torch.Size([167, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 364, total reward: 163.0\n",
            "Episode: 365, total reward: 141.0\n",
            "Episode: 366, total reward: 36.0\n",
            "Episode: 367, total reward: 118.0\n",
            "Episode: 368, total reward: 175.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([175])) that is different to the input size (torch.Size([175, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([115])) that is different to the input size (torch.Size([115, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 369, total reward: 115.0\n",
            "Episode: 370, total reward: 178.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([178])) that is different to the input size (torch.Size([178, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([185])) that is different to the input size (torch.Size([185, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 371, total reward: 185.0\n",
            "Episode: 372, total reward: 156.0\n",
            "Episode: 373, total reward: 200.0\n",
            "Episode: 374, total reward: 185.0\n",
            "Episode: 375, total reward: 200.0\n",
            "Episode: 376, total reward: 121.0\n",
            "Episode: 377, total reward: 125.0\n",
            "Episode: 378, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([121])) that is different to the input size (torch.Size([121, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 379, total reward: 147.0\n",
            "Episode: 380, total reward: 171.0\n",
            "Episode: 381, total reward: 170.0\n",
            "Episode: 382, total reward: 146.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([170])) that is different to the input size (torch.Size([170, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([146])) that is different to the input size (torch.Size([146, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 383, total reward: 200.0\n",
            "Episode: 384, total reward: 138.0\n",
            "Episode: 385, total reward: 200.0\n",
            "Episode: 386, total reward: 132.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([138])) that is different to the input size (torch.Size([138, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 387, total reward: 171.0\n",
            "Episode: 388, total reward: 162.0\n",
            "Episode: 389, total reward: 139.0\n",
            "Episode: 390, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([162])) that is different to the input size (torch.Size([162, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([177])) that is different to the input size (torch.Size([177, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 391, total reward: 177.0\n",
            "Episode: 392, total reward: 200.0\n",
            "Episode: 393, total reward: 126.0\n",
            "Episode: 394, total reward: 149.0\n",
            "Episode: 395, total reward: 200.0\n",
            "Episode: 396, total reward: 125.0\n",
            "Episode: 397, total reward: 170.0\n",
            "Episode: 398, total reward: 141.0\n",
            "Episode: 399, total reward: 200.0\n",
            "Episode: 400, total reward: 169.0\n",
            "Episode: 401, total reward: 200.0\n",
            "Episode: 402, total reward: 69.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([169])) that is different to the input size (torch.Size([169, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([69])) that is different to the input size (torch.Size([69, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([154])) that is different to the input size (torch.Size([154, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 403, total reward: 154.0\n",
            "Episode: 404, total reward: 121.0\n",
            "Episode: 405, total reward: 164.0\n",
            "Episode: 406, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([136])) that is different to the input size (torch.Size([136, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 407, total reward: 136.0\n",
            "Episode: 408, total reward: 200.0\n",
            "Episode: 409, total reward: 120.0\n",
            "Episode: 410, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([199])) that is different to the input size (torch.Size([199, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([166])) that is different to the input size (torch.Size([166, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 411, total reward: 199.0\n",
            "Episode: 412, total reward: 162.0\n",
            "Episode: 413, total reward: 175.0\n",
            "Episode: 414, total reward: 166.0\n",
            "Episode: 415, total reward: 200.0\n",
            "Episode: 416, total reward: 196.0\n",
            "Episode: 417, total reward: 200.0\n",
            "Episode: 418, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([196])) that is different to the input size (torch.Size([196, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([190])) that is different to the input size (torch.Size([190, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 419, total reward: 190.0\n",
            "Episode: 420, total reward: 200.0\n",
            "Episode: 421, total reward: 200.0\n",
            "Episode: 422, total reward: 200.0\n",
            "Episode: 423, total reward: 200.0\n",
            "Episode: 424, total reward: 141.0\n",
            "Episode: 425, total reward: 187.0\n",
            "Episode: 426, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([187])) that is different to the input size (torch.Size([187, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 427, total reward: 151.0\n",
            "Episode: 428, total reward: 138.0\n",
            "Episode: 429, total reward: 200.0\n",
            "Episode: 430, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([172])) that is different to the input size (torch.Size([172, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 431, total reward: 172.0\n",
            "Episode: 432, total reward: 197.0\n",
            "Episode: 433, total reward: 115.0\n",
            "Episode: 434, total reward: 200.0\n",
            "Episode: 435, total reward: 125.0\n",
            "Episode: 436, total reward: 164.0\n",
            "Episode: 437, total reward: 200.0\n",
            "Episode: 438, total reward: 193.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([193])) that is different to the input size (torch.Size([193, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([106])) that is different to the input size (torch.Size([106, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 439, total reward: 124.0\n",
            "Episode: 440, total reward: 106.0\n",
            "Episode: 441, total reward: 200.0\n",
            "Episode: 442, total reward: 106.0\n",
            "Episode: 443, total reward: 190.0\n",
            "Episode: 444, total reward: 110.0\n",
            "Episode: 445, total reward: 112.0\n",
            "Episode: 446, total reward: 180.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([180])) that is different to the input size (torch.Size([180, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([168])) that is different to the input size (torch.Size([168, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 447, total reward: 200.0\n",
            "Episode: 448, total reward: 168.0\n",
            "Episode: 449, total reward: 200.0\n",
            "Episode: 450, total reward: 163.0\n",
            "Episode: 451, total reward: 172.0\n",
            "Episode: 452, total reward: 160.0\n",
            "Episode: 453, total reward: 115.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([160])) that is different to the input size (torch.Size([160, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 454, total reward: 197.0\n",
            "Episode: 455, total reward: 156.0\n",
            "Episode: 456, total reward: 132.0\n",
            "Episode: 457, total reward: 200.0\n",
            "Episode: 458, total reward: 177.0\n",
            "Episode: 459, total reward: 200.0\n",
            "Episode: 460, total reward: 200.0\n",
            "Episode: 461, total reward: 200.0\n",
            "Episode: 462, total reward: 112.0\n",
            "Episode: 463, total reward: 200.0\n",
            "Episode: 464, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([157])) that is different to the input size (torch.Size([157, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 465, total reward: 157.0\n",
            "Episode: 466, total reward: 154.0\n",
            "Episode: 467, total reward: 200.0\n",
            "Episode: 468, total reward: 46.0\n",
            "Episode: 469, total reward: 200.0\n",
            "Episode: 470, total reward: 168.0\n",
            "Episode: 471, total reward: 144.0\n",
            "Episode: 472, total reward: 95.0\n",
            "Episode: 473, total reward: 159.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([144])) that is different to the input size (torch.Size([144, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 474, total reward: 200.0\n",
            "Episode: 475, total reward: 134.0\n",
            "Episode: 476, total reward: 200.0\n",
            "Episode: 477, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([134])) that is different to the input size (torch.Size([134, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 478, total reward: 197.0\n",
            "Episode: 479, total reward: 200.0\n",
            "Episode: 480, total reward: 200.0\n",
            "Episode: 481, total reward: 110.0\n",
            "Episode: 482, total reward: 137.0\n",
            "Episode: 483, total reward: 200.0\n",
            "Episode: 484, total reward: 195.0\n",
            "Episode: 485, total reward: 145.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([195])) that is different to the input size (torch.Size([195, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([176])) that is different to the input size (torch.Size([176, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 486, total reward: 200.0\n",
            "Episode: 487, total reward: 176.0\n",
            "Episode: 488, total reward: 58.0\n",
            "Episode: 489, total reward: 157.0\n",
            "Episode: 490, total reward: 196.0\n",
            "Episode: 491, total reward: 200.0\n",
            "Episode: 492, total reward: 200.0\n",
            "Episode: 493, total reward: 195.0\n",
            "Episode: 494, total reward: 155.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([155])) that is different to the input size (torch.Size([155, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 495, total reward: 200.0\n",
            "Episode: 496, total reward: 200.0\n",
            "Episode: 497, total reward: 157.0\n",
            "Episode: 498, total reward: 200.0\n",
            "Episode: 499, total reward: 175.0\n",
            "Episode: 500, total reward: 200.0\n",
            "Episode: 501, total reward: 196.0\n",
            "Episode: 502, total reward: 200.0\n",
            "Episode: 503, total reward: 193.0\n",
            "Episode: 504, total reward: 200.0\n",
            "Episode: 505, total reward: 165.0\n",
            "Episode: 506, total reward: 134.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([165])) that is different to the input size (torch.Size([165, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 507, total reward: 200.0\n",
            "Episode: 508, total reward: 200.0\n",
            "Episode: 509, total reward: 195.0\n",
            "Episode: 510, total reward: 200.0\n",
            "Episode: 511, total reward: 200.0\n",
            "Episode: 512, total reward: 200.0\n",
            "Episode: 513, total reward: 200.0\n",
            "Episode: 514, total reward: 167.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([153])) that is different to the input size (torch.Size([153, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 515, total reward: 153.0\n",
            "Episode: 516, total reward: 169.0\n",
            "Episode: 517, total reward: 200.0\n",
            "Episode: 518, total reward: 200.0\n",
            "Episode: 519, total reward: 200.0\n",
            "Episode: 520, total reward: 200.0\n",
            "Episode: 521, total reward: 200.0\n",
            "Episode: 522, total reward: 134.0\n",
            "Episode: 523, total reward: 148.0\n",
            "Episode: 524, total reward: 194.0\n",
            "Episode: 525, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([148])) that is different to the input size (torch.Size([148, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([194])) that is different to the input size (torch.Size([194, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 526, total reward: 140.0\n",
            "Episode: 527, total reward: 150.0\n",
            "Episode: 528, total reward: 168.0\n",
            "Episode: 529, total reward: 152.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([152])) that is different to the input size (torch.Size([152, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 530, total reward: 200.0\n",
            "Episode: 531, total reward: 200.0\n",
            "Episode: 532, total reward: 175.0\n",
            "Episode: 533, total reward: 186.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([186])) that is different to the input size (torch.Size([186, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([188])) that is different to the input size (torch.Size([188, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 534, total reward: 200.0\n",
            "Episode: 535, total reward: 188.0\n",
            "Episode: 536, total reward: 177.0\n",
            "Episode: 537, total reward: 195.0\n",
            "Episode: 538, total reward: 200.0\n",
            "Episode: 539, total reward: 135.0\n",
            "Episode: 540, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([135])) that is different to the input size (torch.Size([135, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([192])) that is different to the input size (torch.Size([192, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 541, total reward: 142.0\n",
            "Episode: 542, total reward: 192.0\n",
            "Episode: 543, total reward: 200.0\n",
            "Episode: 544, total reward: 200.0\n",
            "Episode: 545, total reward: 200.0\n",
            "Episode: 546, total reward: 200.0\n",
            "Episode: 547, total reward: 119.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([119])) that is different to the input size (torch.Size([119, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 548, total reward: 143.0\n",
            "Episode: 549, total reward: 200.0\n",
            "Episode: 550, total reward: 200.0\n",
            "Episode: 551, total reward: 178.0\n",
            "Episode: 552, total reward: 134.0\n",
            "Episode: 553, total reward: 200.0\n",
            "Episode: 554, total reward: 113.0\n",
            "Episode: 555, total reward: 200.0\n",
            "Episode: 556, total reward: 200.0\n",
            "Episode: 557, total reward: 120.0\n",
            "Episode: 558, total reward: 160.0\n",
            "Episode: 559, total reward: 200.0\n",
            "Episode: 560, total reward: 200.0\n",
            "Episode: 561, total reward: 200.0\n",
            "Episode: 562, total reward: 200.0\n",
            "Episode: 563, total reward: 200.0\n",
            "Episode: 564, total reward: 135.0\n",
            "Episode: 565, total reward: 200.0\n",
            "Episode: 566, total reward: 200.0\n",
            "Episode: 567, total reward: 196.0\n",
            "Episode: 568, total reward: 200.0\n",
            "Episode: 569, total reward: 171.0\n",
            "Episode: 570, total reward: 200.0\n",
            "Episode: 571, total reward: 134.0\n",
            "Episode: 572, total reward: 200.0\n",
            "Episode: 573, total reward: 166.0\n",
            "Episode: 574, total reward: 200.0\n",
            "Episode: 575, total reward: 200.0\n",
            "Episode: 576, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([198])) that is different to the input size (torch.Size([198, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 577, total reward: 198.0\n",
            "Episode: 578, total reward: 188.0\n",
            "Episode: 579, total reward: 200.0\n",
            "Episode: 580, total reward: 133.0\n",
            "Episode: 581, total reward: 186.0\n",
            "Episode: 582, total reward: 200.0\n",
            "Episode: 583, total reward: 200.0\n",
            "Episode: 584, total reward: 200.0\n",
            "Episode: 585, total reward: 200.0\n",
            "Episode: 586, total reward: 178.0\n",
            "Episode: 587, total reward: 160.0\n",
            "Episode: 588, total reward: 200.0\n",
            "Episode: 589, total reward: 200.0\n",
            "Episode: 590, total reward: 131.0\n",
            "Episode: 591, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([131])) that is different to the input size (torch.Size([131, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 592, total reward: 195.0\n",
            "Episode: 593, total reward: 200.0\n",
            "Episode: 594, total reward: 139.0\n",
            "Episode: 595, total reward: 200.0\n",
            "Episode: 596, total reward: 200.0\n",
            "Episode: 597, total reward: 200.0\n",
            "Episode: 598, total reward: 200.0\n",
            "Episode: 599, total reward: 136.0\n",
            "Episode: 600, total reward: 198.0\n",
            "Episode: 601, total reward: 200.0\n",
            "Episode: 602, total reward: 200.0\n",
            "Episode: 603, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([184])) that is different to the input size (torch.Size([184, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 604, total reward: 184.0\n",
            "Episode: 605, total reward: 200.0\n",
            "Episode: 606, total reward: 200.0\n",
            "Episode: 607, total reward: 159.0\n",
            "Episode: 608, total reward: 183.0\n",
            "Episode: 609, total reward: 200.0\n",
            "Episode: 610, total reward: 200.0\n",
            "Episode: 611, total reward: 200.0\n",
            "Episode: 612, total reward: 200.0\n",
            "Episode: 613, total reward: 200.0\n",
            "Episode: 614, total reward: 200.0\n",
            "Episode: 615, total reward: 200.0\n",
            "Episode: 616, total reward: 189.0\n",
            "Episode: 617, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([189])) that is different to the input size (torch.Size([189, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 618, total reward: 200.0\n",
            "Episode: 619, total reward: 177.0\n",
            "Episode: 620, total reward: 200.0\n",
            "Episode: 621, total reward: 174.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([174])) that is different to the input size (torch.Size([174, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 622, total reward: 197.0\n",
            "Episode: 623, total reward: 185.0\n",
            "Episode: 624, total reward: 200.0\n",
            "Episode: 625, total reward: 200.0\n",
            "Episode: 626, total reward: 200.0\n",
            "Episode: 627, total reward: 148.0\n",
            "Episode: 628, total reward: 200.0\n",
            "Episode: 629, total reward: 200.0\n",
            "Episode: 630, total reward: 140.0\n",
            "Episode: 631, total reward: 200.0\n",
            "Episode: 632, total reward: 200.0\n",
            "Episode: 633, total reward: 200.0\n",
            "Episode: 634, total reward: 200.0\n",
            "Episode: 635, total reward: 173.0\n",
            "Episode: 636, total reward: 200.0\n",
            "Episode: 637, total reward: 200.0\n",
            "Episode: 638, total reward: 200.0\n",
            "Episode: 639, total reward: 200.0\n",
            "Episode: 640, total reward: 200.0\n",
            "Episode: 641, total reward: 200.0\n",
            "Episode: 642, total reward: 200.0\n",
            "Episode: 643, total reward: 153.0\n",
            "Episode: 644, total reward: 200.0\n",
            "Episode: 645, total reward: 200.0\n",
            "Episode: 646, total reward: 200.0\n",
            "Episode: 647, total reward: 200.0\n",
            "Episode: 648, total reward: 200.0\n",
            "Episode: 649, total reward: 200.0\n",
            "Episode: 650, total reward: 200.0\n",
            "Episode: 651, total reward: 200.0\n",
            "Episode: 652, total reward: 200.0\n",
            "Episode: 653, total reward: 200.0\n",
            "Episode: 654, total reward: 200.0\n",
            "Episode: 655, total reward: 200.0\n",
            "Episode: 656, total reward: 200.0\n",
            "Episode: 657, total reward: 183.0\n",
            "Episode: 658, total reward: 129.0\n",
            "Episode: 659, total reward: 200.0\n",
            "Episode: 660, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([129])) that is different to the input size (torch.Size([129, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 661, total reward: 200.0\n",
            "Episode: 662, total reward: 200.0\n",
            "Episode: 663, total reward: 200.0\n",
            "Episode: 664, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([108])) that is different to the input size (torch.Size([108, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 665, total reward: 108.0\n",
            "Episode: 666, total reward: 200.0\n",
            "Episode: 667, total reward: 200.0\n",
            "Episode: 668, total reward: 200.0\n",
            "Episode: 669, total reward: 200.0\n",
            "Episode: 670, total reward: 200.0\n",
            "Episode: 671, total reward: 200.0\n",
            "Episode: 672, total reward: 200.0\n",
            "Episode: 673, total reward: 200.0\n",
            "Episode: 674, total reward: 200.0\n",
            "Episode: 675, total reward: 200.0\n",
            "Episode: 676, total reward: 200.0\n",
            "Episode: 677, total reward: 200.0\n",
            "Episode: 678, total reward: 200.0\n",
            "Episode: 679, total reward: 200.0\n",
            "Episode: 680, total reward: 200.0\n",
            "Episode: 681, total reward: 200.0\n",
            "Episode: 682, total reward: 200.0\n",
            "Episode: 683, total reward: 200.0\n",
            "Episode: 684, total reward: 200.0\n",
            "Episode: 685, total reward: 200.0\n",
            "Episode: 686, total reward: 200.0\n",
            "Episode: 687, total reward: 200.0\n",
            "Episode: 688, total reward: 200.0\n",
            "Episode: 689, total reward: 200.0\n",
            "Episode: 690, total reward: 200.0\n",
            "Episode: 691, total reward: 200.0\n",
            "Episode: 692, total reward: 200.0\n",
            "Episode: 693, total reward: 200.0\n",
            "Episode: 694, total reward: 200.0\n",
            "Episode: 695, total reward: 173.0\n",
            "Episode: 696, total reward: 200.0\n",
            "Episode: 697, total reward: 200.0\n",
            "Episode: 698, total reward: 200.0\n",
            "Episode: 699, total reward: 200.0\n",
            "Episode: 700, total reward: 155.0\n",
            "Episode: 701, total reward: 200.0\n",
            "Episode: 702, total reward: 131.0\n",
            "Episode: 703, total reward: 200.0\n",
            "Episode: 704, total reward: 200.0\n",
            "Episode: 705, total reward: 149.0\n",
            "Episode: 706, total reward: 200.0\n",
            "Episode: 707, total reward: 200.0\n",
            "Episode: 708, total reward: 134.0\n",
            "Episode: 709, total reward: 200.0\n",
            "Episode: 710, total reward: 200.0\n",
            "Episode: 711, total reward: 123.0\n",
            "Episode: 712, total reward: 200.0\n",
            "Episode: 713, total reward: 200.0\n",
            "Episode: 714, total reward: 200.0\n",
            "Episode: 715, total reward: 200.0\n",
            "Episode: 716, total reward: 200.0\n",
            "Episode: 717, total reward: 200.0\n",
            "Episode: 718, total reward: 200.0\n",
            "Episode: 719, total reward: 135.0\n",
            "Episode: 720, total reward: 200.0\n",
            "Episode: 721, total reward: 200.0\n",
            "Episode: 722, total reward: 200.0\n",
            "Episode: 723, total reward: 200.0\n",
            "Episode: 724, total reward: 200.0\n",
            "Episode: 725, total reward: 200.0\n",
            "Episode: 726, total reward: 200.0\n",
            "Episode: 727, total reward: 200.0\n",
            "Episode: 728, total reward: 200.0\n",
            "Episode: 729, total reward: 200.0\n",
            "Episode: 730, total reward: 200.0\n",
            "Episode: 731, total reward: 200.0\n",
            "Episode: 732, total reward: 173.0\n",
            "Episode: 733, total reward: 200.0\n",
            "Episode: 734, total reward: 200.0\n",
            "Episode: 735, total reward: 200.0\n",
            "Episode: 736, total reward: 200.0\n",
            "Episode: 737, total reward: 200.0\n",
            "Episode: 738, total reward: 200.0\n",
            "Episode: 739, total reward: 166.0\n",
            "Episode: 740, total reward: 200.0\n",
            "Episode: 741, total reward: 200.0\n",
            "Episode: 742, total reward: 200.0\n",
            "Episode: 743, total reward: 200.0\n",
            "Episode: 744, total reward: 200.0\n",
            "Episode: 745, total reward: 192.0\n",
            "Episode: 746, total reward: 145.0\n",
            "Episode: 747, total reward: 181.0\n",
            "Episode: 748, total reward: 200.0\n",
            "Episode: 749, total reward: 170.0\n",
            "Episode: 750, total reward: 200.0\n",
            "Episode: 751, total reward: 191.0\n",
            "Episode: 752, total reward: 200.0\n",
            "Episode: 753, total reward: 200.0\n",
            "Episode: 754, total reward: 200.0\n",
            "Episode: 755, total reward: 200.0\n",
            "Episode: 756, total reward: 200.0\n",
            "Episode: 757, total reward: 200.0\n",
            "Episode: 758, total reward: 200.0\n",
            "Episode: 759, total reward: 200.0\n",
            "Episode: 760, total reward: 200.0\n",
            "Episode: 761, total reward: 200.0\n",
            "Episode: 762, total reward: 182.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([182])) that is different to the input size (torch.Size([182, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 763, total reward: 200.0\n",
            "Episode: 764, total reward: 200.0\n",
            "Episode: 765, total reward: 200.0\n",
            "Episode: 766, total reward: 200.0\n",
            "Episode: 767, total reward: 200.0\n",
            "Episode: 768, total reward: 200.0\n",
            "Episode: 769, total reward: 200.0\n",
            "Episode: 770, total reward: 200.0\n",
            "Episode: 771, total reward: 200.0\n",
            "Episode: 772, total reward: 200.0\n",
            "Episode: 773, total reward: 200.0\n",
            "Episode: 774, total reward: 200.0\n",
            "Episode: 775, total reward: 200.0\n",
            "Episode: 776, total reward: 200.0\n",
            "Episode: 777, total reward: 200.0\n",
            "Episode: 778, total reward: 200.0\n",
            "Episode: 779, total reward: 200.0\n",
            "Episode: 780, total reward: 200.0\n",
            "Episode: 781, total reward: 200.0\n",
            "Episode: 782, total reward: 200.0\n",
            "Episode: 783, total reward: 200.0\n",
            "Episode: 784, total reward: 200.0\n",
            "Episode: 785, total reward: 200.0\n",
            "Episode: 786, total reward: 200.0\n",
            "Episode: 787, total reward: 200.0\n",
            "Episode: 788, total reward: 200.0\n",
            "Episode: 789, total reward: 200.0\n",
            "Episode: 790, total reward: 200.0\n",
            "Episode: 791, total reward: 199.0\n",
            "Episode: 792, total reward: 200.0\n",
            "Episode: 793, total reward: 195.0\n",
            "Episode: 794, total reward: 200.0\n",
            "Episode: 795, total reward: 200.0\n",
            "Episode: 796, total reward: 200.0\n",
            "Episode: 797, total reward: 169.0\n",
            "Episode: 798, total reward: 200.0\n",
            "Episode: 799, total reward: 200.0\n",
            "Episode: 800, total reward: 200.0\n",
            "Episode: 801, total reward: 200.0\n",
            "Episode: 802, total reward: 200.0\n",
            "Episode: 803, total reward: 148.0\n",
            "Episode: 804, total reward: 200.0\n",
            "Episode: 805, total reward: 200.0\n",
            "Episode: 806, total reward: 200.0\n",
            "Episode: 807, total reward: 200.0\n",
            "Episode: 808, total reward: 200.0\n",
            "Episode: 809, total reward: 200.0\n",
            "Episode: 810, total reward: 200.0\n",
            "Episode: 811, total reward: 200.0\n",
            "Episode: 812, total reward: 200.0\n",
            "Episode: 813, total reward: 200.0\n",
            "Episode: 814, total reward: 200.0\n",
            "Episode: 815, total reward: 200.0\n",
            "Episode: 816, total reward: 200.0\n",
            "Episode: 817, total reward: 200.0\n",
            "Episode: 818, total reward: 200.0\n",
            "Episode: 819, total reward: 200.0\n",
            "Episode: 820, total reward: 200.0\n",
            "Episode: 821, total reward: 200.0\n",
            "Episode: 822, total reward: 200.0\n",
            "Episode: 823, total reward: 200.0\n",
            "Episode: 824, total reward: 197.0\n",
            "Episode: 825, total reward: 200.0\n",
            "Episode: 826, total reward: 200.0\n",
            "Episode: 827, total reward: 200.0\n",
            "Episode: 828, total reward: 200.0\n",
            "Episode: 829, total reward: 200.0\n",
            "Episode: 830, total reward: 200.0\n",
            "Episode: 831, total reward: 117.0\n",
            "Episode: 832, total reward: 200.0\n",
            "Episode: 833, total reward: 190.0\n",
            "Episode: 834, total reward: 200.0\n",
            "Episode: 835, total reward: 146.0\n",
            "Episode: 836, total reward: 200.0\n",
            "Episode: 837, total reward: 200.0\n",
            "Episode: 838, total reward: 200.0\n",
            "Episode: 839, total reward: 200.0\n",
            "Episode: 840, total reward: 200.0\n",
            "Episode: 841, total reward: 200.0\n",
            "Episode: 842, total reward: 200.0\n",
            "Episode: 843, total reward: 200.0\n",
            "Episode: 844, total reward: 200.0\n",
            "Episode: 845, total reward: 200.0\n",
            "Episode: 846, total reward: 200.0\n",
            "Episode: 847, total reward: 200.0\n",
            "Episode: 848, total reward: 200.0\n",
            "Episode: 849, total reward: 200.0\n",
            "Episode: 850, total reward: 200.0\n",
            "Episode: 851, total reward: 200.0\n",
            "Episode: 852, total reward: 200.0\n",
            "Episode: 853, total reward: 179.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([179])) that is different to the input size (torch.Size([179, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 854, total reward: 200.0\n",
            "Episode: 855, total reward: 200.0\n",
            "Episode: 856, total reward: 200.0\n",
            "Episode: 857, total reward: 200.0\n",
            "Episode: 858, total reward: 200.0\n",
            "Episode: 859, total reward: 200.0\n",
            "Episode: 860, total reward: 200.0\n",
            "Episode: 861, total reward: 200.0\n",
            "Episode: 862, total reward: 200.0\n",
            "Episode: 863, total reward: 200.0\n",
            "Episode: 864, total reward: 200.0\n",
            "Episode: 865, total reward: 200.0\n",
            "Episode: 866, total reward: 200.0\n",
            "Episode: 867, total reward: 200.0\n",
            "Episode: 868, total reward: 200.0\n",
            "Episode: 869, total reward: 200.0\n",
            "Episode: 870, total reward: 200.0\n",
            "Episode: 871, total reward: 200.0\n",
            "Episode: 872, total reward: 168.0\n",
            "Episode: 873, total reward: 200.0\n",
            "Episode: 874, total reward: 200.0\n",
            "Episode: 875, total reward: 200.0\n",
            "Episode: 876, total reward: 200.0\n",
            "Episode: 877, total reward: 200.0\n",
            "Episode: 878, total reward: 200.0\n",
            "Episode: 879, total reward: 200.0\n",
            "Episode: 880, total reward: 200.0\n",
            "Episode: 881, total reward: 200.0\n",
            "Episode: 882, total reward: 200.0\n",
            "Episode: 883, total reward: 200.0\n",
            "Episode: 884, total reward: 200.0\n",
            "Episode: 885, total reward: 200.0\n",
            "Episode: 886, total reward: 200.0\n",
            "Episode: 887, total reward: 200.0\n",
            "Episode: 888, total reward: 200.0\n",
            "Episode: 889, total reward: 200.0\n",
            "Episode: 890, total reward: 200.0\n",
            "Episode: 891, total reward: 200.0\n",
            "Episode: 892, total reward: 200.0\n",
            "Episode: 893, total reward: 200.0\n",
            "Episode: 894, total reward: 200.0\n",
            "Episode: 895, total reward: 200.0\n",
            "Episode: 896, total reward: 200.0\n",
            "Episode: 897, total reward: 200.0\n",
            "Episode: 898, total reward: 200.0\n",
            "Episode: 899, total reward: 200.0\n",
            "Episode: 900, total reward: 200.0\n",
            "Episode: 901, total reward: 200.0\n",
            "Episode: 902, total reward: 187.0\n",
            "Episode: 903, total reward: 200.0\n",
            "Episode: 904, total reward: 200.0\n",
            "Episode: 905, total reward: 200.0\n",
            "Episode: 906, total reward: 200.0\n",
            "Episode: 907, total reward: 200.0\n",
            "Episode: 908, total reward: 200.0\n",
            "Episode: 909, total reward: 200.0\n",
            "Episode: 910, total reward: 200.0\n",
            "Episode: 911, total reward: 200.0\n",
            "Episode: 912, total reward: 200.0\n",
            "Episode: 913, total reward: 200.0\n",
            "Episode: 914, total reward: 200.0\n",
            "Episode: 915, total reward: 200.0\n",
            "Episode: 916, total reward: 200.0\n",
            "Episode: 917, total reward: 200.0\n",
            "Episode: 918, total reward: 200.0\n",
            "Episode: 919, total reward: 200.0\n",
            "Episode: 920, total reward: 200.0\n",
            "Episode: 921, total reward: 200.0\n",
            "Episode: 922, total reward: 200.0\n",
            "Episode: 923, total reward: 200.0\n",
            "Episode: 924, total reward: 200.0\n",
            "Episode: 925, total reward: 200.0\n",
            "Episode: 926, total reward: 200.0\n",
            "Episode: 927, total reward: 200.0\n",
            "Episode: 928, total reward: 200.0\n",
            "Episode: 929, total reward: 200.0\n",
            "Episode: 930, total reward: 200.0\n",
            "Episode: 931, total reward: 200.0\n",
            "Episode: 932, total reward: 200.0\n",
            "Episode: 933, total reward: 200.0\n",
            "Episode: 934, total reward: 200.0\n",
            "Episode: 935, total reward: 200.0\n",
            "Episode: 936, total reward: 200.0\n",
            "Episode: 937, total reward: 200.0\n",
            "Episode: 938, total reward: 200.0\n",
            "Episode: 939, total reward: 200.0\n",
            "Episode: 940, total reward: 200.0\n",
            "Episode: 941, total reward: 200.0\n",
            "Episode: 942, total reward: 200.0\n",
            "Episode: 943, total reward: 200.0\n",
            "Episode: 944, total reward: 200.0\n",
            "Episode: 945, total reward: 200.0\n",
            "Episode: 946, total reward: 200.0\n",
            "Episode: 947, total reward: 200.0\n",
            "Episode: 948, total reward: 200.0\n",
            "Episode: 949, total reward: 200.0\n",
            "Episode: 950, total reward: 200.0\n",
            "Episode: 951, total reward: 200.0\n",
            "Episode: 952, total reward: 200.0\n",
            "Episode: 953, total reward: 183.0\n",
            "Episode: 954, total reward: 200.0\n",
            "Episode: 955, total reward: 200.0\n",
            "Episode: 956, total reward: 200.0\n",
            "Episode: 957, total reward: 200.0\n",
            "Episode: 958, total reward: 200.0\n",
            "Episode: 959, total reward: 162.0\n",
            "Episode: 960, total reward: 200.0\n",
            "Episode: 961, total reward: 200.0\n",
            "Episode: 962, total reward: 200.0\n",
            "Episode: 963, total reward: 200.0\n",
            "Episode: 964, total reward: 200.0\n",
            "Episode: 965, total reward: 200.0\n",
            "Episode: 966, total reward: 200.0\n",
            "Episode: 967, total reward: 200.0\n",
            "Episode: 968, total reward: 200.0\n",
            "Episode: 969, total reward: 200.0\n",
            "Episode: 970, total reward: 200.0\n",
            "Episode: 971, total reward: 200.0\n",
            "Episode: 972, total reward: 200.0\n",
            "Episode: 973, total reward: 171.0\n",
            "Episode: 974, total reward: 200.0\n",
            "Episode: 975, total reward: 200.0\n",
            "Episode: 976, total reward: 200.0\n",
            "Episode: 977, total reward: 200.0\n",
            "Episode: 978, total reward: 200.0\n",
            "Episode: 979, total reward: 200.0\n",
            "Episode: 980, total reward: 200.0\n",
            "Episode: 981, total reward: 200.0\n",
            "Episode: 982, total reward: 200.0\n",
            "Episode: 983, total reward: 200.0\n",
            "Episode: 984, total reward: 200.0\n",
            "Episode: 985, total reward: 200.0\n",
            "Episode: 986, total reward: 200.0\n",
            "Episode: 987, total reward: 200.0\n",
            "Episode: 988, total reward: 185.0\n",
            "Episode: 989, total reward: 200.0\n",
            "Episode: 990, total reward: 200.0\n",
            "Episode: 991, total reward: 200.0\n",
            "Episode: 992, total reward: 200.0\n",
            "Episode: 993, total reward: 200.0\n",
            "Episode: 994, total reward: 200.0\n",
            "Episode: 995, total reward: 200.0\n",
            "Episode: 996, total reward: 200.0\n",
            "Episode: 997, total reward: 200.0\n",
            "Episode: 998, total reward: 200.0\n",
            "Episode: 999, total reward: 200.0\n",
            "Episode: 1000, total reward: 200.0\n",
            "Episode: 1001, total reward: 200.0\n",
            "Episode: 1002, total reward: 200.0\n",
            "Episode: 1003, total reward: 200.0\n",
            "Episode: 1004, total reward: 172.0\n",
            "Episode: 1005, total reward: 200.0\n",
            "Episode: 1006, total reward: 200.0\n",
            "Episode: 1007, total reward: 196.0\n",
            "Episode: 1008, total reward: 200.0\n",
            "Episode: 1009, total reward: 200.0\n",
            "Episode: 1010, total reward: 200.0\n",
            "Episode: 1011, total reward: 200.0\n",
            "Episode: 1012, total reward: 200.0\n",
            "Episode: 1013, total reward: 200.0\n",
            "Episode: 1014, total reward: 200.0\n",
            "Episode: 1015, total reward: 200.0\n",
            "Episode: 1016, total reward: 200.0\n",
            "Episode: 1017, total reward: 200.0\n",
            "Episode: 1018, total reward: 200.0\n",
            "Episode: 1019, total reward: 200.0\n",
            "Episode: 1020, total reward: 200.0\n",
            "Episode: 1021, total reward: 200.0\n",
            "Episode: 1022, total reward: 195.0\n",
            "Episode: 1023, total reward: 200.0\n",
            "Episode: 1024, total reward: 200.0\n",
            "Episode: 1025, total reward: 200.0\n",
            "Episode: 1026, total reward: 200.0\n",
            "Episode: 1027, total reward: 200.0\n",
            "Episode: 1028, total reward: 200.0\n",
            "Episode: 1029, total reward: 200.0\n",
            "Episode: 1030, total reward: 200.0\n",
            "Episode: 1031, total reward: 200.0\n",
            "Episode: 1032, total reward: 200.0\n",
            "Episode: 1033, total reward: 200.0\n",
            "Episode: 1034, total reward: 200.0\n",
            "Episode: 1035, total reward: 200.0\n",
            "Episode: 1036, total reward: 127.0\n",
            "Episode: 1037, total reward: 200.0\n",
            "Episode: 1038, total reward: 200.0\n",
            "Episode: 1039, total reward: 200.0\n",
            "Episode: 1040, total reward: 200.0\n",
            "Episode: 1041, total reward: 200.0\n",
            "Episode: 1042, total reward: 200.0\n",
            "Episode: 1043, total reward: 200.0\n",
            "Episode: 1044, total reward: 200.0\n",
            "Episode: 1045, total reward: 200.0\n",
            "Episode: 1046, total reward: 200.0\n",
            "Episode: 1047, total reward: 200.0\n",
            "Episode: 1048, total reward: 200.0\n",
            "Episode: 1049, total reward: 200.0\n",
            "Episode: 1050, total reward: 200.0\n",
            "Episode: 1051, total reward: 200.0\n",
            "Episode: 1052, total reward: 200.0\n",
            "Episode: 1053, total reward: 200.0\n",
            "Episode: 1054, total reward: 200.0\n",
            "Episode: 1055, total reward: 200.0\n",
            "Episode: 1056, total reward: 200.0\n",
            "Episode: 1057, total reward: 200.0\n",
            "Episode: 1058, total reward: 200.0\n",
            "Episode: 1059, total reward: 200.0\n",
            "Episode: 1060, total reward: 200.0\n",
            "Episode: 1061, total reward: 200.0\n",
            "Episode: 1062, total reward: 200.0\n",
            "Episode: 1063, total reward: 200.0\n",
            "Episode: 1064, total reward: 200.0\n",
            "Episode: 1065, total reward: 200.0\n",
            "Episode: 1066, total reward: 200.0\n",
            "Episode: 1067, total reward: 200.0\n",
            "Episode: 1068, total reward: 200.0\n",
            "Episode: 1069, total reward: 200.0\n",
            "Episode: 1070, total reward: 200.0\n",
            "Episode: 1071, total reward: 200.0\n",
            "Episode: 1072, total reward: 200.0\n",
            "Episode: 1073, total reward: 200.0\n",
            "Episode: 1074, total reward: 200.0\n",
            "Episode: 1075, total reward: 200.0\n",
            "Episode: 1076, total reward: 200.0\n",
            "Episode: 1077, total reward: 200.0\n",
            "Episode: 1078, total reward: 200.0\n",
            "Episode: 1079, total reward: 200.0\n",
            "Episode: 1080, total reward: 200.0\n",
            "Episode: 1081, total reward: 200.0\n",
            "Episode: 1082, total reward: 200.0\n",
            "Episode: 1083, total reward: 182.0\n",
            "Episode: 1084, total reward: 200.0\n",
            "Episode: 1085, total reward: 200.0\n",
            "Episode: 1086, total reward: 200.0\n",
            "Episode: 1087, total reward: 200.0\n",
            "Episode: 1088, total reward: 200.0\n",
            "Episode: 1089, total reward: 200.0\n",
            "Episode: 1090, total reward: 200.0\n",
            "Episode: 1091, total reward: 200.0\n",
            "Episode: 1092, total reward: 200.0\n",
            "Episode: 1093, total reward: 200.0\n",
            "Episode: 1094, total reward: 200.0\n",
            "Episode: 1095, total reward: 200.0\n",
            "Episode: 1096, total reward: 200.0\n",
            "Episode: 1097, total reward: 185.0\n",
            "Episode: 1098, total reward: 200.0\n",
            "Episode: 1099, total reward: 200.0\n",
            "Episode: 1100, total reward: 200.0\n",
            "Episode: 1101, total reward: 200.0\n",
            "Episode: 1102, total reward: 200.0\n",
            "Episode: 1103, total reward: 200.0\n",
            "Episode: 1104, total reward: 200.0\n",
            "Episode: 1105, total reward: 200.0\n",
            "Episode: 1106, total reward: 200.0\n",
            "Episode: 1107, total reward: 200.0\n",
            "Episode: 1108, total reward: 174.0\n",
            "Episode: 1109, total reward: 200.0\n",
            "Episode: 1110, total reward: 200.0\n",
            "Episode: 1111, total reward: 200.0\n",
            "Episode: 1112, total reward: 200.0\n",
            "Episode: 1113, total reward: 200.0\n",
            "Episode: 1114, total reward: 200.0\n",
            "Episode: 1115, total reward: 200.0\n",
            "Episode: 1116, total reward: 200.0\n",
            "Episode: 1117, total reward: 200.0\n",
            "Episode: 1118, total reward: 200.0\n",
            "Episode: 1119, total reward: 200.0\n",
            "Episode: 1120, total reward: 200.0\n",
            "Episode: 1121, total reward: 200.0\n",
            "Episode: 1122, total reward: 200.0\n",
            "Episode: 1123, total reward: 200.0\n",
            "Episode: 1124, total reward: 200.0\n",
            "Episode: 1125, total reward: 200.0\n",
            "Episode: 1126, total reward: 200.0\n",
            "Episode: 1127, total reward: 200.0\n",
            "Episode: 1128, total reward: 200.0\n",
            "Episode: 1129, total reward: 200.0\n",
            "Episode: 1130, total reward: 200.0\n",
            "Episode: 1131, total reward: 200.0\n",
            "Episode: 1132, total reward: 200.0\n",
            "Episode: 1133, total reward: 173.0\n",
            "Episode: 1134, total reward: 200.0\n",
            "Episode: 1135, total reward: 200.0\n",
            "Episode: 1136, total reward: 200.0\n",
            "Episode: 1137, total reward: 200.0\n",
            "Episode: 1138, total reward: 200.0\n",
            "Episode: 1139, total reward: 200.0\n",
            "Episode: 1140, total reward: 200.0\n",
            "Episode: 1141, total reward: 200.0\n",
            "Episode: 1142, total reward: 200.0\n",
            "Episode: 1143, total reward: 200.0\n",
            "Episode: 1144, total reward: 200.0\n",
            "Episode: 1145, total reward: 200.0\n",
            "Episode: 1146, total reward: 140.0\n",
            "Episode: 1147, total reward: 200.0\n",
            "Episode: 1148, total reward: 200.0\n",
            "Episode: 1149, total reward: 200.0\n",
            "Episode: 1150, total reward: 161.0\n",
            "Episode: 1151, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([161])) that is different to the input size (torch.Size([161, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1152, total reward: 200.0\n",
            "Episode: 1153, total reward: 200.0\n",
            "Episode: 1154, total reward: 200.0\n",
            "Episode: 1155, total reward: 200.0\n",
            "Episode: 1156, total reward: 200.0\n",
            "Episode: 1157, total reward: 200.0\n",
            "Episode: 1158, total reward: 200.0\n",
            "Episode: 1159, total reward: 200.0\n",
            "Episode: 1160, total reward: 200.0\n",
            "Episode: 1161, total reward: 200.0\n",
            "Episode: 1162, total reward: 200.0\n",
            "Episode: 1163, total reward: 199.0\n",
            "Episode: 1164, total reward: 200.0\n",
            "Episode: 1165, total reward: 200.0\n",
            "Episode: 1166, total reward: 200.0\n",
            "Episode: 1167, total reward: 200.0\n",
            "Episode: 1168, total reward: 200.0\n",
            "Episode: 1169, total reward: 200.0\n",
            "Episode: 1170, total reward: 200.0\n",
            "Episode: 1171, total reward: 200.0\n",
            "Episode: 1172, total reward: 200.0\n",
            "Episode: 1173, total reward: 200.0\n",
            "Episode: 1174, total reward: 197.0\n",
            "Episode: 1175, total reward: 200.0\n",
            "Episode: 1176, total reward: 200.0\n",
            "Episode: 1177, total reward: 188.0\n",
            "Episode: 1178, total reward: 200.0\n",
            "Episode: 1179, total reward: 200.0\n",
            "Episode: 1180, total reward: 200.0\n",
            "Episode: 1181, total reward: 200.0\n",
            "Episode: 1182, total reward: 200.0\n",
            "Episode: 1183, total reward: 200.0\n",
            "Episode: 1184, total reward: 200.0\n",
            "Episode: 1185, total reward: 200.0\n",
            "Episode: 1186, total reward: 200.0\n",
            "Episode: 1187, total reward: 161.0\n",
            "Episode: 1188, total reward: 200.0\n",
            "Episode: 1189, total reward: 200.0\n",
            "Episode: 1190, total reward: 200.0\n",
            "Episode: 1191, total reward: 200.0\n",
            "Episode: 1192, total reward: 200.0\n",
            "Episode: 1193, total reward: 200.0\n",
            "Episode: 1194, total reward: 200.0\n",
            "Episode: 1195, total reward: 200.0\n",
            "Episode: 1196, total reward: 200.0\n",
            "Episode: 1197, total reward: 200.0\n",
            "Episode: 1198, total reward: 200.0\n",
            "Episode: 1199, total reward: 200.0\n",
            "Episode: 1200, total reward: 200.0\n",
            "Episode: 1201, total reward: 200.0\n",
            "Episode: 1202, total reward: 200.0\n",
            "Episode: 1203, total reward: 200.0\n",
            "Episode: 1204, total reward: 200.0\n",
            "Episode: 1205, total reward: 200.0\n",
            "Episode: 1206, total reward: 200.0\n",
            "Episode: 1207, total reward: 200.0\n",
            "Episode: 1208, total reward: 200.0\n",
            "Episode: 1209, total reward: 200.0\n",
            "Episode: 1210, total reward: 200.0\n",
            "Episode: 1211, total reward: 200.0\n",
            "Episode: 1212, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1213, total reward: 128.0\n",
            "Episode: 1214, total reward: 200.0\n",
            "Episode: 1215, total reward: 200.0\n",
            "Episode: 1216, total reward: 200.0\n",
            "Episode: 1217, total reward: 200.0\n",
            "Episode: 1218, total reward: 200.0\n",
            "Episode: 1219, total reward: 200.0\n",
            "Episode: 1220, total reward: 200.0\n",
            "Episode: 1221, total reward: 200.0\n",
            "Episode: 1222, total reward: 200.0\n",
            "Episode: 1223, total reward: 200.0\n",
            "Episode: 1224, total reward: 200.0\n",
            "Episode: 1225, total reward: 200.0\n",
            "Episode: 1226, total reward: 200.0\n",
            "Episode: 1227, total reward: 200.0\n",
            "Episode: 1228, total reward: 200.0\n",
            "Episode: 1229, total reward: 200.0\n",
            "Episode: 1230, total reward: 200.0\n",
            "Episode: 1231, total reward: 200.0\n",
            "Episode: 1232, total reward: 200.0\n",
            "Episode: 1233, total reward: 200.0\n",
            "Episode: 1234, total reward: 200.0\n",
            "Episode: 1235, total reward: 200.0\n",
            "Episode: 1236, total reward: 200.0\n",
            "Episode: 1237, total reward: 163.0\n",
            "Episode: 1238, total reward: 200.0\n",
            "Episode: 1239, total reward: 200.0\n",
            "Episode: 1240, total reward: 200.0\n",
            "Episode: 1241, total reward: 200.0\n",
            "Episode: 1242, total reward: 196.0\n",
            "Episode: 1243, total reward: 200.0\n",
            "Episode: 1244, total reward: 200.0\n",
            "Episode: 1245, total reward: 200.0\n",
            "Episode: 1246, total reward: 200.0\n",
            "Episode: 1247, total reward: 200.0\n",
            "Episode: 1248, total reward: 200.0\n",
            "Episode: 1249, total reward: 200.0\n",
            "Episode: 1250, total reward: 200.0\n",
            "Episode: 1251, total reward: 200.0\n",
            "Episode: 1252, total reward: 200.0\n",
            "Episode: 1253, total reward: 200.0\n",
            "Episode: 1254, total reward: 200.0\n",
            "Episode: 1255, total reward: 200.0\n",
            "Episode: 1256, total reward: 200.0\n",
            "Episode: 1257, total reward: 200.0\n",
            "Episode: 1258, total reward: 200.0\n",
            "Episode: 1259, total reward: 200.0\n",
            "Episode: 1260, total reward: 200.0\n",
            "Episode: 1261, total reward: 200.0\n",
            "Episode: 1262, total reward: 200.0\n",
            "Episode: 1263, total reward: 200.0\n",
            "Episode: 1264, total reward: 200.0\n",
            "Episode: 1265, total reward: 200.0\n",
            "Episode: 1266, total reward: 200.0\n",
            "Episode: 1267, total reward: 200.0\n",
            "Episode: 1268, total reward: 200.0\n",
            "Episode: 1269, total reward: 200.0\n",
            "Episode: 1270, total reward: 200.0\n",
            "Episode: 1271, total reward: 200.0\n",
            "Episode: 1272, total reward: 200.0\n",
            "Episode: 1273, total reward: 200.0\n",
            "Episode: 1274, total reward: 200.0\n",
            "Episode: 1275, total reward: 200.0\n",
            "Episode: 1276, total reward: 200.0\n",
            "Episode: 1277, total reward: 200.0\n",
            "Episode: 1278, total reward: 200.0\n",
            "Episode: 1279, total reward: 200.0\n",
            "Episode: 1280, total reward: 200.0\n",
            "Episode: 1281, total reward: 200.0\n",
            "Episode: 1282, total reward: 200.0\n",
            "Episode: 1283, total reward: 200.0\n",
            "Episode: 1284, total reward: 200.0\n",
            "Episode: 1285, total reward: 200.0\n",
            "Episode: 1286, total reward: 200.0\n",
            "Episode: 1287, total reward: 200.0\n",
            "Episode: 1288, total reward: 200.0\n",
            "Episode: 1289, total reward: 200.0\n",
            "Episode: 1290, total reward: 200.0\n",
            "Episode: 1291, total reward: 200.0\n",
            "Episode: 1292, total reward: 200.0\n",
            "Episode: 1293, total reward: 200.0\n",
            "Episode: 1294, total reward: 200.0\n",
            "Episode: 1295, total reward: 200.0\n",
            "Episode: 1296, total reward: 200.0\n",
            "Episode: 1297, total reward: 200.0\n",
            "Episode: 1298, total reward: 200.0\n",
            "Episode: 1299, total reward: 200.0\n",
            "Episode: 1300, total reward: 200.0\n",
            "Episode: 1301, total reward: 200.0\n",
            "Episode: 1302, total reward: 200.0\n",
            "Episode: 1303, total reward: 200.0\n",
            "Episode: 1304, total reward: 200.0\n",
            "Episode: 1305, total reward: 200.0\n",
            "Episode: 1306, total reward: 200.0\n",
            "Episode: 1307, total reward: 200.0\n",
            "Episode: 1308, total reward: 200.0\n",
            "Episode: 1309, total reward: 200.0\n",
            "Episode: 1310, total reward: 200.0\n",
            "Episode: 1311, total reward: 200.0\n",
            "Episode: 1312, total reward: 200.0\n",
            "Episode: 1313, total reward: 200.0\n",
            "Episode: 1314, total reward: 200.0\n",
            "Episode: 1315, total reward: 200.0\n",
            "Episode: 1316, total reward: 200.0\n",
            "Episode: 1317, total reward: 200.0\n",
            "Episode: 1318, total reward: 200.0\n",
            "Episode: 1319, total reward: 200.0\n",
            "Episode: 1320, total reward: 200.0\n",
            "Episode: 1321, total reward: 200.0\n",
            "Episode: 1322, total reward: 200.0\n",
            "Episode: 1323, total reward: 200.0\n",
            "Episode: 1324, total reward: 200.0\n",
            "Episode: 1325, total reward: 200.0\n",
            "Episode: 1326, total reward: 200.0\n",
            "Episode: 1327, total reward: 200.0\n",
            "Episode: 1328, total reward: 200.0\n",
            "Episode: 1329, total reward: 200.0\n",
            "Episode: 1330, total reward: 200.0\n",
            "Episode: 1331, total reward: 200.0\n",
            "Episode: 1332, total reward: 200.0\n",
            "Episode: 1333, total reward: 200.0\n",
            "Episode: 1334, total reward: 200.0\n",
            "Episode: 1335, total reward: 200.0\n",
            "Episode: 1336, total reward: 200.0\n",
            "Episode: 1337, total reward: 200.0\n",
            "Episode: 1338, total reward: 200.0\n",
            "Episode: 1339, total reward: 200.0\n",
            "Episode: 1340, total reward: 200.0\n",
            "Episode: 1341, total reward: 200.0\n",
            "Episode: 1342, total reward: 200.0\n",
            "Episode: 1343, total reward: 200.0\n",
            "Episode: 1344, total reward: 200.0\n",
            "Episode: 1345, total reward: 200.0\n",
            "Episode: 1346, total reward: 200.0\n",
            "Episode: 1347, total reward: 200.0\n",
            "Episode: 1348, total reward: 200.0\n",
            "Episode: 1349, total reward: 200.0\n",
            "Episode: 1350, total reward: 200.0\n",
            "Episode: 1351, total reward: 200.0\n",
            "Episode: 1352, total reward: 200.0\n",
            "Episode: 1353, total reward: 200.0\n",
            "Episode: 1354, total reward: 200.0\n",
            "Episode: 1355, total reward: 200.0\n",
            "Episode: 1356, total reward: 200.0\n",
            "Episode: 1357, total reward: 200.0\n",
            "Episode: 1358, total reward: 200.0\n",
            "Episode: 1359, total reward: 200.0\n",
            "Episode: 1360, total reward: 200.0\n",
            "Episode: 1361, total reward: 200.0\n",
            "Episode: 1362, total reward: 200.0\n",
            "Episode: 1363, total reward: 200.0\n",
            "Episode: 1364, total reward: 200.0\n",
            "Episode: 1365, total reward: 200.0\n",
            "Episode: 1366, total reward: 200.0\n",
            "Episode: 1367, total reward: 200.0\n",
            "Episode: 1368, total reward: 200.0\n",
            "Episode: 1369, total reward: 200.0\n",
            "Episode: 1370, total reward: 200.0\n",
            "Episode: 1371, total reward: 200.0\n",
            "Episode: 1372, total reward: 200.0\n",
            "Episode: 1373, total reward: 200.0\n",
            "Episode: 1374, total reward: 200.0\n",
            "Episode: 1375, total reward: 200.0\n",
            "Episode: 1376, total reward: 200.0\n",
            "Episode: 1377, total reward: 200.0\n",
            "Episode: 1378, total reward: 200.0\n",
            "Episode: 1379, total reward: 200.0\n",
            "Episode: 1380, total reward: 200.0\n",
            "Episode: 1381, total reward: 200.0\n",
            "Episode: 1382, total reward: 200.0\n",
            "Episode: 1383, total reward: 200.0\n",
            "Episode: 1384, total reward: 200.0\n",
            "Episode: 1385, total reward: 200.0\n",
            "Episode: 1386, total reward: 200.0\n",
            "Episode: 1387, total reward: 200.0\n",
            "Episode: 1388, total reward: 200.0\n",
            "Episode: 1389, total reward: 200.0\n",
            "Episode: 1390, total reward: 200.0\n",
            "Episode: 1391, total reward: 200.0\n",
            "Episode: 1392, total reward: 200.0\n",
            "Episode: 1393, total reward: 200.0\n",
            "Episode: 1394, total reward: 200.0\n",
            "Episode: 1395, total reward: 200.0\n",
            "Episode: 1396, total reward: 200.0\n",
            "Episode: 1397, total reward: 200.0\n",
            "Episode: 1398, total reward: 200.0\n",
            "Episode: 1399, total reward: 200.0\n",
            "Episode: 1400, total reward: 200.0\n",
            "Episode: 1401, total reward: 200.0\n",
            "Episode: 1402, total reward: 200.0\n",
            "Episode: 1403, total reward: 200.0\n",
            "Episode: 1404, total reward: 200.0\n",
            "Episode: 1405, total reward: 200.0\n",
            "Episode: 1406, total reward: 200.0\n",
            "Episode: 1407, total reward: 200.0\n",
            "Episode: 1408, total reward: 200.0\n",
            "Episode: 1409, total reward: 200.0\n",
            "Episode: 1410, total reward: 200.0\n",
            "Episode: 1411, total reward: 200.0\n",
            "Episode: 1412, total reward: 200.0\n",
            "Episode: 1413, total reward: 200.0\n",
            "Episode: 1414, total reward: 200.0\n",
            "Episode: 1415, total reward: 200.0\n",
            "Episode: 1416, total reward: 200.0\n",
            "Episode: 1417, total reward: 200.0\n",
            "Episode: 1418, total reward: 200.0\n",
            "Episode: 1419, total reward: 200.0\n",
            "Episode: 1420, total reward: 200.0\n",
            "Episode: 1421, total reward: 200.0\n",
            "Episode: 1422, total reward: 200.0\n",
            "Episode: 1423, total reward: 200.0\n",
            "Episode: 1424, total reward: 200.0\n",
            "Episode: 1425, total reward: 200.0\n",
            "Episode: 1426, total reward: 200.0\n",
            "Episode: 1427, total reward: 200.0\n",
            "Episode: 1428, total reward: 200.0\n",
            "Episode: 1429, total reward: 200.0\n",
            "Episode: 1430, total reward: 200.0\n",
            "Episode: 1431, total reward: 200.0\n",
            "Episode: 1432, total reward: 200.0\n",
            "Episode: 1433, total reward: 200.0\n",
            "Episode: 1434, total reward: 200.0\n",
            "Episode: 1435, total reward: 200.0\n",
            "Episode: 1436, total reward: 108.0\n",
            "Episode: 1437, total reward: 200.0\n",
            "Episode: 1438, total reward: 200.0\n",
            "Episode: 1439, total reward: 200.0\n",
            "Episode: 1440, total reward: 200.0\n",
            "Episode: 1441, total reward: 200.0\n",
            "Episode: 1442, total reward: 200.0\n",
            "Episode: 1443, total reward: 200.0\n",
            "Episode: 1444, total reward: 200.0\n",
            "Episode: 1445, total reward: 200.0\n",
            "Episode: 1446, total reward: 200.0\n",
            "Episode: 1447, total reward: 200.0\n",
            "Episode: 1448, total reward: 200.0\n",
            "Episode: 1449, total reward: 200.0\n",
            "Episode: 1450, total reward: 200.0\n",
            "Episode: 1451, total reward: 200.0\n",
            "Episode: 1452, total reward: 200.0\n",
            "Episode: 1453, total reward: 200.0\n",
            "Episode: 1454, total reward: 200.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([130])) that is different to the input size (torch.Size([130, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1455, total reward: 130.0\n",
            "Episode: 1456, total reward: 200.0\n",
            "Episode: 1457, total reward: 200.0\n",
            "Episode: 1458, total reward: 200.0\n",
            "Episode: 1459, total reward: 200.0\n",
            "Episode: 1460, total reward: 200.0\n",
            "Episode: 1461, total reward: 174.0\n",
            "Episode: 1462, total reward: 200.0\n",
            "Episode: 1463, total reward: 200.0\n",
            "Episode: 1464, total reward: 200.0\n",
            "Episode: 1465, total reward: 200.0\n",
            "Episode: 1466, total reward: 200.0\n",
            "Episode: 1467, total reward: 200.0\n",
            "Episode: 1468, total reward: 200.0\n",
            "Episode: 1469, total reward: 200.0\n",
            "Episode: 1470, total reward: 200.0\n",
            "Episode: 1471, total reward: 200.0\n",
            "Episode: 1472, total reward: 200.0\n",
            "Episode: 1473, total reward: 200.0\n",
            "Episode: 1474, total reward: 200.0\n",
            "Episode: 1475, total reward: 200.0\n",
            "Episode: 1476, total reward: 200.0\n",
            "Episode: 1477, total reward: 200.0\n",
            "Episode: 1478, total reward: 200.0\n",
            "Episode: 1479, total reward: 200.0\n",
            "Episode: 1480, total reward: 200.0\n",
            "Episode: 1481, total reward: 200.0\n",
            "Episode: 1482, total reward: 200.0\n",
            "Episode: 1483, total reward: 200.0\n",
            "Episode: 1484, total reward: 200.0\n",
            "Episode: 1485, total reward: 200.0\n",
            "Episode: 1486, total reward: 200.0\n",
            "Episode: 1487, total reward: 200.0\n",
            "Episode: 1488, total reward: 200.0\n",
            "Episode: 1489, total reward: 200.0\n",
            "Episode: 1490, total reward: 200.0\n",
            "Episode: 1491, total reward: 200.0\n",
            "Episode: 1492, total reward: 200.0\n",
            "Episode: 1493, total reward: 200.0\n",
            "Episode: 1494, total reward: 200.0\n",
            "Episode: 1495, total reward: 200.0\n",
            "Episode: 1496, total reward: 200.0\n",
            "Episode: 1497, total reward: 200.0\n",
            "Episode: 1498, total reward: 200.0\n",
            "Episode: 1499, total reward: 200.0\n",
            "Episode: 1500, total reward: 200.0\n",
            "Episode: 1501, total reward: 200.0\n",
            "Episode: 1502, total reward: 200.0\n",
            "Episode: 1503, total reward: 200.0\n",
            "Episode: 1504, total reward: 200.0\n",
            "Episode: 1505, total reward: 200.0\n",
            "Episode: 1506, total reward: 200.0\n",
            "Episode: 1507, total reward: 200.0\n",
            "Episode: 1508, total reward: 200.0\n",
            "Episode: 1509, total reward: 200.0\n",
            "Episode: 1510, total reward: 200.0\n",
            "Episode: 1511, total reward: 200.0\n",
            "Episode: 1512, total reward: 200.0\n",
            "Episode: 1513, total reward: 200.0\n",
            "Episode: 1514, total reward: 200.0\n",
            "Episode: 1515, total reward: 200.0\n",
            "Episode: 1516, total reward: 200.0\n",
            "Episode: 1517, total reward: 200.0\n",
            "Episode: 1518, total reward: 200.0\n",
            "Episode: 1519, total reward: 200.0\n",
            "Episode: 1520, total reward: 200.0\n",
            "Episode: 1521, total reward: 200.0\n",
            "Episode: 1522, total reward: 200.0\n",
            "Episode: 1523, total reward: 200.0\n",
            "Episode: 1524, total reward: 200.0\n",
            "Episode: 1525, total reward: 200.0\n",
            "Episode: 1526, total reward: 200.0\n",
            "Episode: 1527, total reward: 200.0\n",
            "Episode: 1528, total reward: 200.0\n",
            "Episode: 1529, total reward: 200.0\n",
            "Episode: 1530, total reward: 200.0\n",
            "Episode: 1531, total reward: 200.0\n",
            "Episode: 1532, total reward: 200.0\n",
            "Episode: 1533, total reward: 200.0\n",
            "Episode: 1534, total reward: 200.0\n",
            "Episode: 1535, total reward: 200.0\n",
            "Episode: 1536, total reward: 194.0\n",
            "Episode: 1537, total reward: 200.0\n",
            "Episode: 1538, total reward: 200.0\n",
            "Episode: 1539, total reward: 200.0\n",
            "Episode: 1540, total reward: 200.0\n",
            "Episode: 1541, total reward: 200.0\n",
            "Episode: 1542, total reward: 200.0\n",
            "Episode: 1543, total reward: 200.0\n",
            "Episode: 1544, total reward: 200.0\n",
            "Episode: 1545, total reward: 200.0\n",
            "Episode: 1546, total reward: 200.0\n",
            "Episode: 1547, total reward: 156.0\n",
            "Episode: 1548, total reward: 200.0\n",
            "Episode: 1549, total reward: 200.0\n",
            "Episode: 1550, total reward: 200.0\n",
            "Episode: 1551, total reward: 200.0\n",
            "Episode: 1552, total reward: 200.0\n",
            "Episode: 1553, total reward: 200.0\n",
            "Episode: 1554, total reward: 200.0\n",
            "Episode: 1555, total reward: 200.0\n",
            "Episode: 1556, total reward: 200.0\n",
            "Episode: 1557, total reward: 200.0\n",
            "Episode: 1558, total reward: 200.0\n",
            "Episode: 1559, total reward: 200.0\n",
            "Episode: 1560, total reward: 200.0\n",
            "Episode: 1561, total reward: 200.0\n",
            "Episode: 1562, total reward: 200.0\n",
            "Episode: 1563, total reward: 200.0\n",
            "Episode: 1564, total reward: 200.0\n",
            "Episode: 1565, total reward: 200.0\n",
            "Episode: 1566, total reward: 200.0\n",
            "Episode: 1567, total reward: 200.0\n",
            "Episode: 1568, total reward: 200.0\n",
            "Episode: 1569, total reward: 200.0\n",
            "Episode: 1570, total reward: 200.0\n",
            "Episode: 1571, total reward: 200.0\n",
            "Episode: 1572, total reward: 200.0\n",
            "Episode: 1573, total reward: 200.0\n",
            "Episode: 1574, total reward: 200.0\n",
            "Episode: 1575, total reward: 200.0\n",
            "Episode: 1576, total reward: 200.0\n",
            "Episode: 1577, total reward: 200.0\n",
            "Episode: 1578, total reward: 200.0\n",
            "Episode: 1579, total reward: 200.0\n",
            "Episode: 1580, total reward: 200.0\n",
            "Episode: 1581, total reward: 200.0\n",
            "Episode: 1582, total reward: 200.0\n",
            "Episode: 1583, total reward: 200.0\n",
            "Episode: 1584, total reward: 200.0\n",
            "Episode: 1585, total reward: 200.0\n",
            "Episode: 1586, total reward: 200.0\n",
            "Episode: 1587, total reward: 200.0\n",
            "Episode: 1588, total reward: 200.0\n",
            "Episode: 1589, total reward: 200.0\n",
            "Episode: 1590, total reward: 200.0\n",
            "Episode: 1591, total reward: 200.0\n",
            "Episode: 1592, total reward: 200.0\n",
            "Episode: 1593, total reward: 200.0\n",
            "Episode: 1594, total reward: 200.0\n",
            "Episode: 1595, total reward: 200.0\n",
            "Episode: 1596, total reward: 200.0\n",
            "Episode: 1597, total reward: 200.0\n",
            "Episode: 1598, total reward: 200.0\n",
            "Episode: 1599, total reward: 200.0\n",
            "Episode: 1600, total reward: 200.0\n",
            "Episode: 1601, total reward: 200.0\n",
            "Episode: 1602, total reward: 200.0\n",
            "Episode: 1603, total reward: 200.0\n",
            "Episode: 1604, total reward: 200.0\n",
            "Episode: 1605, total reward: 200.0\n",
            "Episode: 1606, total reward: 200.0\n",
            "Episode: 1607, total reward: 200.0\n",
            "Episode: 1608, total reward: 200.0\n",
            "Episode: 1609, total reward: 200.0\n",
            "Episode: 1610, total reward: 200.0\n",
            "Episode: 1611, total reward: 200.0\n",
            "Episode: 1612, total reward: 200.0\n",
            "Episode: 1613, total reward: 200.0\n",
            "Episode: 1614, total reward: 200.0\n",
            "Episode: 1615, total reward: 200.0\n",
            "Episode: 1616, total reward: 200.0\n",
            "Episode: 1617, total reward: 200.0\n",
            "Episode: 1618, total reward: 200.0\n",
            "Episode: 1619, total reward: 200.0\n",
            "Episode: 1620, total reward: 200.0\n",
            "Episode: 1621, total reward: 200.0\n",
            "Episode: 1622, total reward: 200.0\n",
            "Episode: 1623, total reward: 200.0\n",
            "Episode: 1624, total reward: 200.0\n",
            "Episode: 1625, total reward: 200.0\n",
            "Episode: 1626, total reward: 200.0\n",
            "Episode: 1627, total reward: 200.0\n",
            "Episode: 1628, total reward: 200.0\n",
            "Episode: 1629, total reward: 200.0\n",
            "Episode: 1630, total reward: 200.0\n",
            "Episode: 1631, total reward: 200.0\n",
            "Episode: 1632, total reward: 200.0\n",
            "Episode: 1633, total reward: 200.0\n",
            "Episode: 1634, total reward: 200.0\n",
            "Episode: 1635, total reward: 200.0\n",
            "Episode: 1636, total reward: 200.0\n",
            "Episode: 1637, total reward: 200.0\n",
            "Episode: 1638, total reward: 200.0\n",
            "Episode: 1639, total reward: 200.0\n",
            "Episode: 1640, total reward: 200.0\n",
            "Episode: 1641, total reward: 200.0\n",
            "Episode: 1642, total reward: 200.0\n",
            "Episode: 1643, total reward: 200.0\n",
            "Episode: 1644, total reward: 200.0\n",
            "Episode: 1645, total reward: 200.0\n",
            "Episode: 1646, total reward: 200.0\n",
            "Episode: 1647, total reward: 200.0\n",
            "Episode: 1648, total reward: 200.0\n",
            "Episode: 1649, total reward: 200.0\n",
            "Episode: 1650, total reward: 200.0\n",
            "Episode: 1651, total reward: 200.0\n",
            "Episode: 1652, total reward: 200.0\n",
            "Episode: 1653, total reward: 200.0\n",
            "Episode: 1654, total reward: 200.0\n",
            "Episode: 1655, total reward: 200.0\n",
            "Episode: 1656, total reward: 200.0\n",
            "Episode: 1657, total reward: 200.0\n",
            "Episode: 1658, total reward: 200.0\n",
            "Episode: 1659, total reward: 200.0\n",
            "Episode: 1660, total reward: 200.0\n",
            "Episode: 1661, total reward: 200.0\n",
            "Episode: 1662, total reward: 200.0\n",
            "Episode: 1663, total reward: 200.0\n",
            "Episode: 1664, total reward: 200.0\n",
            "Episode: 1665, total reward: 200.0\n",
            "Episode: 1666, total reward: 200.0\n",
            "Episode: 1667, total reward: 200.0\n",
            "Episode: 1668, total reward: 200.0\n",
            "Episode: 1669, total reward: 200.0\n",
            "Episode: 1670, total reward: 200.0\n",
            "Episode: 1671, total reward: 200.0\n",
            "Episode: 1672, total reward: 200.0\n",
            "Episode: 1673, total reward: 200.0\n",
            "Episode: 1674, total reward: 200.0\n",
            "Episode: 1675, total reward: 200.0\n",
            "Episode: 1676, total reward: 200.0\n",
            "Episode: 1677, total reward: 200.0\n",
            "Episode: 1678, total reward: 200.0\n",
            "Episode: 1679, total reward: 200.0\n",
            "Episode: 1680, total reward: 200.0\n",
            "Episode: 1681, total reward: 200.0\n",
            "Episode: 1682, total reward: 200.0\n",
            "Episode: 1683, total reward: 200.0\n",
            "Episode: 1684, total reward: 200.0\n",
            "Episode: 1685, total reward: 200.0\n",
            "Episode: 1686, total reward: 200.0\n",
            "Episode: 1687, total reward: 200.0\n",
            "Episode: 1688, total reward: 200.0\n",
            "Episode: 1689, total reward: 200.0\n",
            "Episode: 1690, total reward: 200.0\n",
            "Episode: 1691, total reward: 200.0\n",
            "Episode: 1692, total reward: 200.0\n",
            "Episode: 1693, total reward: 200.0\n",
            "Episode: 1694, total reward: 200.0\n",
            "Episode: 1695, total reward: 200.0\n",
            "Episode: 1696, total reward: 200.0\n",
            "Episode: 1697, total reward: 200.0\n",
            "Episode: 1698, total reward: 200.0\n",
            "Episode: 1699, total reward: 200.0\n",
            "Episode: 1700, total reward: 200.0\n",
            "Episode: 1701, total reward: 200.0\n",
            "Episode: 1702, total reward: 200.0\n",
            "Episode: 1703, total reward: 200.0\n",
            "Episode: 1704, total reward: 200.0\n",
            "Episode: 1705, total reward: 200.0\n",
            "Episode: 1706, total reward: 200.0\n",
            "Episode: 1707, total reward: 200.0\n",
            "Episode: 1708, total reward: 200.0\n",
            "Episode: 1709, total reward: 200.0\n",
            "Episode: 1710, total reward: 200.0\n",
            "Episode: 1711, total reward: 200.0\n",
            "Episode: 1712, total reward: 200.0\n",
            "Episode: 1713, total reward: 200.0\n",
            "Episode: 1714, total reward: 200.0\n",
            "Episode: 1715, total reward: 200.0\n",
            "Episode: 1716, total reward: 200.0\n",
            "Episode: 1717, total reward: 200.0\n",
            "Episode: 1718, total reward: 200.0\n",
            "Episode: 1719, total reward: 169.0\n",
            "Episode: 1720, total reward: 200.0\n",
            "Episode: 1721, total reward: 200.0\n",
            "Episode: 1722, total reward: 200.0\n",
            "Episode: 1723, total reward: 200.0\n",
            "Episode: 1724, total reward: 200.0\n",
            "Episode: 1725, total reward: 200.0\n",
            "Episode: 1726, total reward: 200.0\n",
            "Episode: 1727, total reward: 200.0\n",
            "Episode: 1728, total reward: 200.0\n",
            "Episode: 1729, total reward: 200.0\n",
            "Episode: 1730, total reward: 200.0\n",
            "Episode: 1731, total reward: 200.0\n",
            "Episode: 1732, total reward: 200.0\n",
            "Episode: 1733, total reward: 200.0\n",
            "Episode: 1734, total reward: 200.0\n",
            "Episode: 1735, total reward: 200.0\n",
            "Episode: 1736, total reward: 200.0\n",
            "Episode: 1737, total reward: 200.0\n",
            "Episode: 1738, total reward: 200.0\n",
            "Episode: 1739, total reward: 200.0\n",
            "Episode: 1740, total reward: 200.0\n",
            "Episode: 1741, total reward: 200.0\n",
            "Episode: 1742, total reward: 200.0\n",
            "Episode: 1743, total reward: 200.0\n",
            "Episode: 1744, total reward: 200.0\n",
            "Episode: 1745, total reward: 200.0\n",
            "Episode: 1746, total reward: 200.0\n",
            "Episode: 1747, total reward: 200.0\n",
            "Episode: 1748, total reward: 200.0\n",
            "Episode: 1749, total reward: 200.0\n",
            "Episode: 1750, total reward: 200.0\n",
            "Episode: 1751, total reward: 200.0\n",
            "Episode: 1752, total reward: 200.0\n",
            "Episode: 1753, total reward: 200.0\n",
            "Episode: 1754, total reward: 200.0\n",
            "Episode: 1755, total reward: 200.0\n",
            "Episode: 1756, total reward: 200.0\n",
            "Episode: 1757, total reward: 200.0\n",
            "Episode: 1758, total reward: 200.0\n",
            "Episode: 1759, total reward: 200.0\n",
            "Episode: 1760, total reward: 200.0\n",
            "Episode: 1761, total reward: 200.0\n",
            "Episode: 1762, total reward: 200.0\n",
            "Episode: 1763, total reward: 200.0\n",
            "Episode: 1764, total reward: 200.0\n",
            "Episode: 1765, total reward: 200.0\n",
            "Episode: 1766, total reward: 200.0\n",
            "Episode: 1767, total reward: 200.0\n",
            "Episode: 1768, total reward: 200.0\n",
            "Episode: 1769, total reward: 200.0\n",
            "Episode: 1770, total reward: 200.0\n",
            "Episode: 1771, total reward: 200.0\n",
            "Episode: 1772, total reward: 200.0\n",
            "Episode: 1773, total reward: 200.0\n",
            "Episode: 1774, total reward: 200.0\n",
            "Episode: 1775, total reward: 200.0\n",
            "Episode: 1776, total reward: 200.0\n",
            "Episode: 1777, total reward: 200.0\n",
            "Episode: 1778, total reward: 200.0\n",
            "Episode: 1779, total reward: 200.0\n",
            "Episode: 1780, total reward: 200.0\n",
            "Episode: 1781, total reward: 200.0\n",
            "Episode: 1782, total reward: 200.0\n",
            "Episode: 1783, total reward: 200.0\n",
            "Episode: 1784, total reward: 200.0\n",
            "Episode: 1785, total reward: 200.0\n",
            "Episode: 1786, total reward: 200.0\n",
            "Episode: 1787, total reward: 200.0\n",
            "Episode: 1788, total reward: 200.0\n",
            "Episode: 1789, total reward: 200.0\n",
            "Episode: 1790, total reward: 200.0\n",
            "Episode: 1791, total reward: 200.0\n",
            "Episode: 1792, total reward: 200.0\n",
            "Episode: 1793, total reward: 200.0\n",
            "Episode: 1794, total reward: 200.0\n",
            "Episode: 1795, total reward: 200.0\n",
            "Episode: 1796, total reward: 200.0\n",
            "Episode: 1797, total reward: 200.0\n",
            "Episode: 1798, total reward: 200.0\n",
            "Episode: 1799, total reward: 200.0\n",
            "Episode: 1800, total reward: 200.0\n",
            "Episode: 1801, total reward: 200.0\n",
            "Episode: 1802, total reward: 200.0\n",
            "Episode: 1803, total reward: 200.0\n",
            "Episode: 1804, total reward: 200.0\n",
            "Episode: 1805, total reward: 200.0\n",
            "Episode: 1806, total reward: 200.0\n",
            "Episode: 1807, total reward: 200.0\n",
            "Episode: 1808, total reward: 200.0\n",
            "Episode: 1809, total reward: 200.0\n",
            "Episode: 1810, total reward: 200.0\n",
            "Episode: 1811, total reward: 200.0\n",
            "Episode: 1812, total reward: 200.0\n",
            "Episode: 1813, total reward: 200.0\n",
            "Episode: 1814, total reward: 200.0\n",
            "Episode: 1815, total reward: 200.0\n",
            "Episode: 1816, total reward: 200.0\n",
            "Episode: 1817, total reward: 200.0\n",
            "Episode: 1818, total reward: 200.0\n",
            "Episode: 1819, total reward: 200.0\n",
            "Episode: 1820, total reward: 200.0\n",
            "Episode: 1821, total reward: 200.0\n",
            "Episode: 1822, total reward: 200.0\n",
            "Episode: 1823, total reward: 200.0\n",
            "Episode: 1824, total reward: 200.0\n",
            "Episode: 1825, total reward: 200.0\n",
            "Episode: 1826, total reward: 200.0\n",
            "Episode: 1827, total reward: 200.0\n",
            "Episode: 1828, total reward: 200.0\n",
            "Episode: 1829, total reward: 200.0\n",
            "Episode: 1830, total reward: 200.0\n",
            "Episode: 1831, total reward: 200.0\n",
            "Episode: 1832, total reward: 200.0\n",
            "Episode: 1833, total reward: 200.0\n",
            "Episode: 1834, total reward: 200.0\n",
            "Episode: 1835, total reward: 200.0\n",
            "Episode: 1836, total reward: 200.0\n",
            "Episode: 1837, total reward: 200.0\n",
            "Episode: 1838, total reward: 200.0\n",
            "Episode: 1839, total reward: 200.0\n",
            "Episode: 1840, total reward: 200.0\n",
            "Episode: 1841, total reward: 200.0\n",
            "Episode: 1842, total reward: 200.0\n",
            "Episode: 1843, total reward: 200.0\n",
            "Episode: 1844, total reward: 200.0\n",
            "Episode: 1845, total reward: 200.0\n",
            "Episode: 1846, total reward: 200.0\n",
            "Episode: 1847, total reward: 200.0\n",
            "Episode: 1848, total reward: 200.0\n",
            "Episode: 1849, total reward: 200.0\n",
            "Episode: 1850, total reward: 200.0\n",
            "Episode: 1851, total reward: 200.0\n",
            "Episode: 1852, total reward: 200.0\n",
            "Episode: 1853, total reward: 200.0\n",
            "Episode: 1854, total reward: 200.0\n",
            "Episode: 1855, total reward: 200.0\n",
            "Episode: 1856, total reward: 200.0\n",
            "Episode: 1857, total reward: 200.0\n",
            "Episode: 1858, total reward: 200.0\n",
            "Episode: 1859, total reward: 200.0\n",
            "Episode: 1860, total reward: 200.0\n",
            "Episode: 1861, total reward: 200.0\n",
            "Episode: 1862, total reward: 200.0\n",
            "Episode: 1863, total reward: 200.0\n",
            "Episode: 1864, total reward: 200.0\n",
            "Episode: 1865, total reward: 200.0\n",
            "Episode: 1866, total reward: 200.0\n",
            "Episode: 1867, total reward: 200.0\n",
            "Episode: 1868, total reward: 200.0\n",
            "Episode: 1869, total reward: 200.0\n",
            "Episode: 1870, total reward: 200.0\n",
            "Episode: 1871, total reward: 200.0\n",
            "Episode: 1872, total reward: 200.0\n",
            "Episode: 1873, total reward: 200.0\n",
            "Episode: 1874, total reward: 200.0\n",
            "Episode: 1875, total reward: 200.0\n",
            "Episode: 1876, total reward: 200.0\n",
            "Episode: 1877, total reward: 200.0\n",
            "Episode: 1878, total reward: 200.0\n",
            "Episode: 1879, total reward: 200.0\n",
            "Episode: 1880, total reward: 200.0\n",
            "Episode: 1881, total reward: 200.0\n",
            "Episode: 1882, total reward: 200.0\n",
            "Episode: 1883, total reward: 200.0\n",
            "Episode: 1884, total reward: 200.0\n",
            "Episode: 1885, total reward: 200.0\n",
            "Episode: 1886, total reward: 200.0\n",
            "Episode: 1887, total reward: 200.0\n",
            "Episode: 1888, total reward: 200.0\n",
            "Episode: 1889, total reward: 200.0\n",
            "Episode: 1890, total reward: 200.0\n",
            "Episode: 1891, total reward: 200.0\n",
            "Episode: 1892, total reward: 200.0\n",
            "Episode: 1893, total reward: 200.0\n",
            "Episode: 1894, total reward: 200.0\n",
            "Episode: 1895, total reward: 200.0\n",
            "Episode: 1896, total reward: 200.0\n",
            "Episode: 1897, total reward: 200.0\n",
            "Episode: 1898, total reward: 200.0\n",
            "Episode: 1899, total reward: 200.0\n",
            "Episode: 1900, total reward: 200.0\n",
            "Episode: 1901, total reward: 200.0\n",
            "Episode: 1902, total reward: 200.0\n",
            "Episode: 1903, total reward: 200.0\n",
            "Episode: 1904, total reward: 200.0\n",
            "Episode: 1905, total reward: 200.0\n",
            "Episode: 1906, total reward: 200.0\n",
            "Episode: 1907, total reward: 200.0\n",
            "Episode: 1908, total reward: 195.0\n",
            "Episode: 1909, total reward: 200.0\n",
            "Episode: 1910, total reward: 200.0\n",
            "Episode: 1911, total reward: 200.0\n",
            "Episode: 1912, total reward: 200.0\n",
            "Episode: 1913, total reward: 200.0\n",
            "Episode: 1914, total reward: 200.0\n",
            "Episode: 1915, total reward: 200.0\n",
            "Episode: 1916, total reward: 200.0\n",
            "Episode: 1917, total reward: 200.0\n",
            "Episode: 1918, total reward: 200.0\n",
            "Episode: 1919, total reward: 200.0\n",
            "Episode: 1920, total reward: 200.0\n",
            "Episode: 1921, total reward: 200.0\n",
            "Episode: 1922, total reward: 200.0\n",
            "Episode: 1923, total reward: 200.0\n",
            "Episode: 1924, total reward: 200.0\n",
            "Episode: 1925, total reward: 200.0\n",
            "Episode: 1926, total reward: 200.0\n",
            "Episode: 1927, total reward: 200.0\n",
            "Episode: 1928, total reward: 200.0\n",
            "Episode: 1929, total reward: 200.0\n",
            "Episode: 1930, total reward: 200.0\n",
            "Episode: 1931, total reward: 200.0\n",
            "Episode: 1932, total reward: 200.0\n",
            "Episode: 1933, total reward: 200.0\n",
            "Episode: 1934, total reward: 200.0\n",
            "Episode: 1935, total reward: 200.0\n",
            "Episode: 1936, total reward: 200.0\n",
            "Episode: 1937, total reward: 200.0\n",
            "Episode: 1938, total reward: 200.0\n",
            "Episode: 1939, total reward: 200.0\n",
            "Episode: 1940, total reward: 200.0\n",
            "Episode: 1941, total reward: 200.0\n",
            "Episode: 1942, total reward: 200.0\n",
            "Episode: 1943, total reward: 200.0\n",
            "Episode: 1944, total reward: 200.0\n",
            "Episode: 1945, total reward: 200.0\n",
            "Episode: 1946, total reward: 200.0\n",
            "Episode: 1947, total reward: 200.0\n",
            "Episode: 1948, total reward: 200.0\n",
            "Episode: 1949, total reward: 200.0\n",
            "Episode: 1950, total reward: 200.0\n",
            "Episode: 1951, total reward: 200.0\n",
            "Episode: 1952, total reward: 200.0\n",
            "Episode: 1953, total reward: 200.0\n",
            "Episode: 1954, total reward: 200.0\n",
            "Episode: 1955, total reward: 200.0\n",
            "Episode: 1956, total reward: 200.0\n",
            "Episode: 1957, total reward: 200.0\n",
            "Episode: 1958, total reward: 200.0\n",
            "Episode: 1959, total reward: 191.0\n",
            "Episode: 1960, total reward: 200.0\n",
            "Episode: 1961, total reward: 200.0\n",
            "Episode: 1962, total reward: 200.0\n",
            "Episode: 1963, total reward: 200.0\n",
            "Episode: 1964, total reward: 200.0\n",
            "Episode: 1965, total reward: 200.0\n",
            "Episode: 1966, total reward: 200.0\n",
            "Episode: 1967, total reward: 200.0\n",
            "Episode: 1968, total reward: 200.0\n",
            "Episode: 1969, total reward: 200.0\n",
            "Episode: 1970, total reward: 200.0\n",
            "Episode: 1971, total reward: 200.0\n",
            "Episode: 1972, total reward: 200.0\n",
            "Episode: 1973, total reward: 200.0\n",
            "Episode: 1974, total reward: 181.0\n",
            "Episode: 1975, total reward: 200.0\n",
            "Episode: 1976, total reward: 200.0\n",
            "Episode: 1977, total reward: 200.0\n",
            "Episode: 1978, total reward: 200.0\n",
            "Episode: 1979, total reward: 200.0\n",
            "Episode: 1980, total reward: 200.0\n",
            "Episode: 1981, total reward: 200.0\n",
            "Episode: 1982, total reward: 200.0\n",
            "Episode: 1983, total reward: 200.0\n",
            "Episode: 1984, total reward: 200.0\n",
            "Episode: 1985, total reward: 197.0\n",
            "Episode: 1986, total reward: 200.0\n",
            "Episode: 1987, total reward: 200.0\n",
            "Episode: 1988, total reward: 200.0\n",
            "Episode: 1989, total reward: 200.0\n",
            "Episode: 1990, total reward: 200.0\n",
            "Episode: 1991, total reward: 200.0\n",
            "Episode: 1992, total reward: 200.0\n",
            "Episode: 1993, total reward: 200.0\n",
            "Episode: 1994, total reward: 200.0\n",
            "Episode: 1995, total reward: 200.0\n",
            "Episode: 1996, total reward: 200.0\n",
            "Episode: 1997, total reward: 200.0\n",
            "Episode: 1998, total reward: 200.0\n",
            "Episode: 1999, total reward: 200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(total_reward_episode)\n",
        "plt.title('Episode reward over time')\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total reward')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "_Lob07qzrt7C",
        "outputId": "a95cfd3c-8214-4ad4-935f-d44f55f827e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}