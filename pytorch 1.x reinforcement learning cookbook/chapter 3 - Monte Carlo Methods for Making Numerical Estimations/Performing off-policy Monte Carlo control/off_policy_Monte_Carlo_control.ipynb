{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "off-policy Monte Carlo control.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import the necessary modules "
      ],
      "metadata": {
        "id": "GpyLXJUN8d_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gym\n",
        "from collections import defaultdict\n",
        "env = gym.make('Blackjack-v0')"
      ],
      "metadata": {
        "id": "E5sO4vNT8ZAZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define behavior policy"
      ],
      "metadata": {
        "id": "KWQcXViQzY_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_random_policy(n_action):\n",
        "  probs = torch.ones(n_action) / n_action\n",
        "  def policy_function(state):\n",
        "    return probs\n",
        "  return policy_function\n",
        "random_policy = gen_random_policy(env.action_space.n)"
      ],
      "metadata": {
        "id": "fVwtY6aVzcpd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "use on-policy for choosing action"
      ],
      "metadata": {
        "id": "aQBbD8CRKiv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_episode(env, behavior_policy):\n",
        "  state = env.reset()\n",
        "  rewards = []\n",
        "  actions = []\n",
        "  states = []\n",
        "  is_done = False\n",
        "  while not is_done:\n",
        "    probs = behavior_policy(state)\n",
        "    action = torch.multinomial(probs, 1).item()\n",
        "    actions.append(action)\n",
        "    states.append(state)\n",
        "    state, reward, is_done, info = env.step(action)\n",
        "    rewards.append(reward)\n",
        "    if is_done:\n",
        "      break\n",
        "  return states, actions, rewards"
      ],
      "metadata": {
        "id": "dB4JBAAo-SP1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mc_control_off_policy(env, gamma, n_episode, behavior_policy):\n",
        "  n_action = env.action_space.n\n",
        "  G_sum = defaultdict(float)\n",
        "  N = defaultdict(int)\n",
        "  Q = defaultdict(lambda: torch.empty(n_action))\n",
        "  for episode in range(n_episode):\n",
        "    W = {}\n",
        "    w = 1\n",
        "    states_t, actions_t, rewards_t = run_episode(env, behavior_policy)\n",
        "    return_t = 0\n",
        "    G = {}\n",
        "    for state_t, action_t, reward_t in zip(states_t[::-1], actions_t[::-1], rewards_t[::-1]):\n",
        "      return_t = gamma * return_t + reward_t\n",
        "      G[(state_t, action_t)] = return_t\n",
        "      if action_t != torch.argmax(Q[state_t]).item():\n",
        "        break\n",
        "      w *= 1./ behavior_policy(state_t)[action_t]\n",
        "    for state_action, return_t in G.items():\n",
        "      state, action = state_action\n",
        "      if state[0] <= 21:\n",
        "        G_sum[state_action] += return_t * W[state_action]\n",
        "        N[state_action] += 1\n",
        "        Q[state][action] = G_sum[state_action] / N[state_action]\n",
        "  policy = {}\n",
        "  for state, actions in Q.items():\n",
        "    policy[state] = torch.argmax(actions).item()\n",
        "  return Q, policy"
      ],
      "metadata": {
        "id": "LkpEspkLQnIQ"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}